{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b0R18qGjOxT"
      },
      "source": [
        "<center>\n",
        "<h1 style=\"font-family:verdana\">\n",
        " üíª üßë Reconeixement d'entitats anomenades üßë üíª\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZOmxM4_kAUC"
      },
      "source": [
        "<p> üéØ <b>Objectiu</b>: en aquesta segona part de la pr√†ctica aprendrem a recon√®ixer entitats anomenades, √©s a dir, identificar i classificar entitats en una oraci√≥ que poden ser (en el context de reserva de vols) la ciutat de sortida o d'arribada, la data del mes i el dia, si es de negocis o turista o altres categories espec√≠fiques. Aquesta tasca se sol plantejar etiquetant cada paraula amb una etiqueta de la categoria de l'entitat a la qual correspon.\n",
        "\n",
        "Tant la classificaci√≥ d'intencions (tasca estudiada a la primera part) com el reconeixement d'entitats anomenades (Name Entity Recognition, NER) que veurem en aquesta part s√≥n components crucials dels sistemes de processament del llenguatge natural (Natural Language Processing, NLP) i sovint s'utilitzen junts per crear aplicacions d'intel¬∑lig√®ncia artificial (IA) conversacionals m√©s sofisticades. Per exemple, en un xatbot, la classificaci√≥ d'intencions ajuda a entendre la intenci√≥ principal de l'usuari, mentre que el reconeixement d'entitats anomenades ajuda a extreure entitats rellevants per proporcionar respostes m√©s contextualitzades.\n",
        "\n",
        "\n",
        "<p> ‚ú® <b>Contingut</b>: els passos d'aquesta segona part seran similars a la primera. En primer lloc, analitzarem el conjunt de dades. En segon lloc, prepararem les dades per a poder entrenar el model. I finalment dissenyarem l'arquitectura i entrenarem el model. </p>\n",
        "\n",
        "\n",
        "<p> ‚úè <b>Exercicis</b>: en cada secci√≥ anireu trobant exercicis que haureu d'anar resolent. </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI_K-e1cmXlb"
      },
      "source": [
        "---\n",
        "\n",
        "<h2> √çndex </h2>\n",
        "\n",
        "1. [Inspecci√≥ del conjunt de dades](#section-one)\n",
        "  * [Exercici 1](#ex-one)\n",
        "  * [Exercici 2](#ex-two)\n",
        "2. [Preprocessament de dades](#section-two)\n",
        "  * [Exercici 3](#ex-three)\n",
        "  * [Exercici 4](#ex-four)\n",
        "3. [Disseny del model i entrenament](#section-three)\n",
        "  * [Exercici 5](#ex-five)\n",
        "  * [Exercici 6](#ex-six)\n",
        "4. [Lliurable](#section-four)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKn_1FnTxvfV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swhc9NwqpUs8"
      },
      "source": [
        "<h1><a name=\"section-one\"> 1. Inspecci√≥ del conjunt de dades </a></h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSM223cvp7wJ",
        "outputId": "607b716d-b1f9-496f-dc7c-7eebdf01ced2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1u2wzXvsuscLeFHwXcDwMDaNDy0u_99-t\n",
            "To: /content/nlu_ATIS_data.tar.gz\n",
            "100% 122k/122k [00:00<00:00, 129MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!gdown \"https://drive.google.com/uc?id=1u2wzXvsuscLeFHwXcDwMDaNDy0u_99-t\"\n",
        "!tar -zxf nlu_ATIS_data.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAp0lemwjd71",
        "outputId": "556551c4-0370-4482-ff81-9b2c6a34f80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.csv  train.csv\n"
          ]
        }
      ],
      "source": [
        "!ls data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqKtLqYUpWkZ"
      },
      "source": [
        "En aquesta segona part de la pr√†ctica utilitzarem el mateix dataset que a la primera part, per√≤ en aquest cas utilitzarem la **primera columna** que correspon a les **oracions** introdu√Ødes pels usuaris i la **segona columna** on trobarem les oracions d'entrada en format **BILOU**.\n",
        "\n",
        "El format BILOU  √©s un esquema d'etiquetatge que es fa servir a les tasques de reconeixement d'entitats anomenades. El nom *BILOU* representa les etiquetes utilitzades en aquest esquema:\n",
        "\n",
        "*   **B** - Beginning: primer token d'una entitat.\n",
        "*   **I** - Inside: token dins d'una entitat.\n",
        "*   **L** - Last: √∫ltim token de l'entitat.\n",
        "*   **O** - Outside: token que no pertany a cap entitat.\n",
        "*   **U** - Unit: entitats d'un sol token\n",
        "\n",
        "A continuaci√≥, carregarem les dades per visualitzar i poder entendre millor aquestes etiquetes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fUGDuD9wUfm"
      },
      "source": [
        "---\n",
        "\n",
        " <h1><a name=\"ex-one\"><center> ‚úè Exercici 1 ‚úè</a></h1>\n",
        "\n",
        "A continuaci√≥ us demanem que carregueu els dos CSVs de la carpeta `data`: `train.csv`, `test.csv` utilitzant pandas. Recorda que aquests CSVs no tenen cap√ßalera. Agafeu les 900 √∫ltimes lineas del fitxer `train.csv` per crear un dataframe per validaci√≥."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93lI2dDVxmST",
        "outputId": "668fec1c-b813-4e88-d217-f83707ea1005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 4078\n",
            "Validation dataset size: 900\n",
            "Test dataset size: 893\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "train_data = pd.read_csv('./data/train.csv', header=None)\n",
        "val_data = train_data.tail(900)\n",
        "train_data = pd.read_csv('./data/train.csv', header=None, nrows=4078)\n",
        "test_data = pd.read_csv('./data/test.csv', header=None)\n",
        "\n",
        "print('Training size:', len(train_data))\n",
        "print('Validation dataset size:', len(val_data))\n",
        "print('Test dataset size:', len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CugYB4oNyFju"
      },
      "source": [
        "---\n",
        "\n",
        " <h1><a name=\"ex-two\"><center> ‚úè Exercici 2 ‚úè</a></h1>\n",
        "\n",
        "Tal com hem introdu√Øt abans, per a aquest exercici ens centrarem en la **primera** i la **segona** columna. Per tant, ara us demanem que guardeu en les seg√ºents variables, les llistes corresponents a les oracions i a les etiquetes de les tres particions (`train`, `validation` i `test`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edw3mK_Hy-M3"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "train_sentences = list(train_data[0])\n",
        "train_labels = list(train_data[1])\n",
        "\n",
        "val_sentences = list(val_data[0])\n",
        "val_labels = list(val_data[1])\n",
        "\n",
        "test_sentences = list(test_data[0])\n",
        "test_labels = list(test_data[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKgiGo7UzYDU"
      },
      "source": [
        "---\n",
        "\n",
        "Si tot ha anat b√© ja podem analitzar quin aspecte t√© el format BILOU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgjKAyCUzp_M",
        "outputId": "305bddb9-517b-4c47-85eb-445542242d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i want to fly from boston at 838 am and arrive in denver at 1110 in the morning\n",
            " \"O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day\"\n"
          ]
        }
      ],
      "source": [
        "print(train_sentences[0])\n",
        "print(train_labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWzA_MPL02kk"
      },
      "source": [
        "Aquest hauria de ser el resultat obtingut si executeu la cel¬∑la anterior:\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "i want to fly from boston at 838 am and arrive in denver at 1110 in the morning\n",
        " \"O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day\"\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "En aquest exemple, `boston` i `838 am` corresponen a l'entitat \"ciutat de sortida\" i a l'entitat \"hora de sortida\" respectivament (`fromloc.city_name`,`depart_time.time`). `838` correspon al primer token que pertany la entitat `depart_time.time` i `am` al segon de la mateixa entitat. Els tokens com `i` o `want` no pertanyen a cap entitat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BuHmIx62MUA",
        "outputId": "15a0b10d-4a6c-4a5e-fd1c-c7ebe37944b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what flights are available from pittsburgh to baltimore on thursday morning\n",
            " \"O O O O O B-fromloc.city_name O B-toloc.city_name O B-depart_date.day_name B-depart_time.period_of_day\"\n"
          ]
        }
      ],
      "source": [
        "print(train_sentences[1])\n",
        "print(train_labels[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSWlVauS2gll"
      },
      "source": [
        "I aquest hauria de ser el resultat de la cel¬∑la anterior:\n",
        "\n",
        "```\n",
        "what flights are available from pittsburgh to baltimore on thursday morning\n",
        " O O O O O B-fromloc.city_name O B-toloc.city_name O B-depart_date.day_name B-depart_time.period_of_day\n",
        "```\n",
        "\n",
        "En l'anterior exemple, `what`, `flights`, `are`, `available`, `from`, `to` i `on` estan etiquetades com a no pertanyents a cap entitat. I, en canvi, `pittsburgh` pertany a l'entitat d'un sol token anomenada ciutat d'arribada (`toloc.city_name`). Tamb√© hi ha entitats compostes com `baltimore` que pertany a l'entitat ciutat de sortida (`fromloc.city_name`) i `thursday morning` que pertanyen a les entitats data de sortida (`depart_date.day_name`, `depart_time.period_of_day`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hwZtqaI7rOQ"
      },
      "source": [
        "Vegem-ne la llista completa d'entitats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VDzOwWk4Ee2",
        "outputId": "d405eb37-45db-412e-b9bf-353bbd473cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different entities: 216\n",
            "Unique entities: ['\"O', 'O', 'B-fromloc.city_name', 'B-depart_time.time', 'I-depart_time.time', 'B-toloc.city_name', 'B-arrive_time.time', 'B-arrive_time.period_of_day\"', 'B-depart_date.day_name', 'B-depart_time.period_of_day\"', 'B-flight_time', 'I-flight_time', 'I-fromloc.city_name', 'B-fromloc.city_name\"', '\"B-cost_relative', 'B-toloc.city_name\"', '\"B-round_trip', 'I-round_trip', 'B-cost_relative', 'B-fare_amount', 'I-fare_amount\"', 'B-depart_date.today_relative', 'I-toloc.city_name', 'B-depart_date.day_name\"', 'B-city_name\"', 'I-toloc.city_name\"', 'B-stoploc.city_name\"', 'B-toloc.airport_code\"', 'B-depart_time.time_relative', 'I-depart_time.time\"', 'B-class_type', 'I-class_type', 'B-depart_date.date_relative', 'O\"', 'B-airline_name', 'I-airline_name\"', '\"B-city_name', 'B-arrive_time.time_relative', 'B-arrive_time.time\"', 'B-round_trip', 'I-airline_name', 'B-depart_time.start_time', 'I-depart_time.start_time', 'B-depart_time.end_time', 'I-depart_time.end_time', 'B-fromloc.airport_name', 'I-fromloc.airport_name', 'B-toloc.state_name', 'B-depart_date.day_number', 'I-depart_date.day_number', 'B-depart_date.month_name\"', 'B-mod', 'B-stoploc.city_name', '\"B-fromloc.city_name', 'B-fare_basis_code\"', 'B-depart_date.month_name', 'B-depart_date.day_number\"', 'B-transport_type', 'B-flight_mod', 'I-cost_relative', 'B-depart_time.period_of_day', 'B-arrive_date.month_name', 'B-arrive_date.day_number\"', 'B-toloc.state_name\"', 'B-depart_date.today_relative\"', 'B-meal\"', 'B-fare_basis_code', 'B-toloc.state_code\"', 'B-toloc.airport_code', 'B-meal_description\"', 'B-return_date.month_name', 'B-return_date.day_number\"', 'I-fromloc.airport_name\"', 'B-meal', 'B-airline_code', 'I-depart_date.day_number\"', 'B-depart_time.period_mod', 'I-arrive_time.time\"', 'B-flight_stop', 'I-arrive_time.time', 'B-city_name', 'I-city_name\"', 'B-fromloc.airport_code', 'B-meal_description', 'B-arrive_date.day_name\"', 'B-time', 'B-or', 'B-arrive_date.day_name', 'B-arrive_date.day_number', 'I-arrive_date.day_number\"', 'B-toloc.state_code', 'I-fare_amount', 'I-city_name', 'B-economy', 'I-economy', 'B-flight_number', 'I-depart_time.end_time\"', 'B-arrive_time.period_mod', 'B-arrive_time.period_of_day', '\"B-airline_name', 'B-depart_time.time\"', 'I-transport_type', '\"B-flight_mod', 'B-fare_amount\"', 'B-flight_days', 'B-flight_days\"', 'I-stoploc.city_name', 'B-airline_code\"', 'B-toloc.airport_name', 'I-toloc.airport_name', 'B-flight_stop\"', 'B-state_code\"', 'I-toloc.airport_name\"', 'I-flight_stop\"', 'B-arrive_time.start_time', 'B-arrive_time.end_time', 'I-arrive_time.end_time\"', 'B-flight_number\"', 'B-fromloc.state_name', 'I-fromloc.state_name', 'B-arrive_date.date_relative', 'I-stoploc.city_name\"', 'B-depart_date.year\"', 'I-economy\"', 'B-return_date.date_relative', 'B-airport_code', 'B-aircraft_code\"', 'B-airport_code\"', 'B-fromloc.state_code', 'B-aircraft_code', 'B-airline_name\"', 'I-round_trip\"', 'B-connect', 'I-fromloc.city_name\"', '\"B-class_type', 'I-class_type\"', 'I-flight_stop', 'I-arrive_time.start_time', '\"B-economy', '\"B-depart_date.day_name', 'B-restriction_code', 'I-restriction_code', '\"B-flight_stop', 'I-restriction_code\"', 'B-depart_time.time_relative\"', 'I-toloc.state_name\"', 'B-airport_name', 'I-airport_name', 'I-airport_name\"', 'B-toloc.country_name', 'B-days_code\"', 'I-fare_basis_code', 'I-arrive_time.time_relative', '\"B-depart_time.period_of_day', 'B-transport_type\"', 'B-depart_date.year', 'I-arrive_time.period_of_day\"', 'I-depart_time.time_relative', '\"B-airline_code', '\"B-depart_time.time', 'B-return_date.date_relative\"', 'B-day_name', 'B-period_of_day\"', 'I-toloc.state_name', 'B-flight_mod\"', 'I-depart_date.day_name', 'B-restriction_code\"', 'B-round_trip\"', 'B-today_relative\"', 'B-stoploc.state_code\"', 'B-fromloc.state_name\"', 'B-meal_code', 'I-meal_code', 'B-today_relative', 'I-today_relative', 'I-today_relative\"', 'I-flight_mod', 'I-flight_mod\"', 'B-state_name\"', '\"B-fromloc.airport_code', 'B-stoploc.airport_name\"', 'B-arrive_date.today_relative\"', '\"B-transport_type', '\"O\"', '\"B-depart_time.time_relative', 'I-arrive_time.period_of_day', 'I-transport_type\"', 'B-flight_time\"', 'B-stoploc.state_code', 'B-period_of_day', 'B-time_relative', 'I-time\"', 'B-return_time.period_of_day', 'B-return_date.day_number', 'I-return_date.day_number\"', 'B-connect\"', 'I-depart_time.period_of_day', 'B-cost_relative\"', 'I-meal_code\"', 'B-return_time.period_mod', 'B-return_time.period_of_day\"', '\"B-mod', '\"B-flight_time', 'B-toloc.airport_name\"', 'I-depart_date.today_relative', 'I-depart_date.today_relative\"', 'B-fromloc.state_code\"', 'I-mod\"', 'I-depart_time.period_of_day\"', 'B-day_name\"', 'B-month_name', 'B-day_number', 'B-state_code', '\"B-depart_date.date_relative', 'I-return_date.date_relative', 'I-return_date.date_relative\"']\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def count_unique_entities(list_of_label_sentences):\n",
        "  flat_labels = []\n",
        "  for labels in list_of_label_sentences:\n",
        "    flat_labels += labels.split()\n",
        "  c = Counter(flat_labels)\n",
        "  return len(c), list(c.keys())\n",
        "\n",
        "num_unique_entities, unique_entities = count_unique_entities(train_labels)\n",
        "\n",
        "print(\"Number of different entities:\", num_unique_entities)\n",
        "\n",
        "print(\"Unique entities:\", unique_entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wlsgR88_D8g"
      },
      "source": [
        "<h1><a name=\"section-two\"> 2. Preprocessament de dades </a></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8yM79_n_OPA"
      },
      "source": [
        "El processament de les dades ser√† semblant al de la primera part d'aquesta pr√†ctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLrvW1frMus9"
      },
      "source": [
        "---\n",
        "\n",
        " <h1><a name=\"ex-three\"><center> ‚úè Exercici 3 ‚úè</a></h1>\n",
        "\n",
        "En aquest exercici us demanem que realitzeu els passos seg√ºents per preparar les dades.\n",
        "\n",
        " 1. El primer pas ser√† construir el vocabulari a partir de les paraules presents a les oracions d'entrenament.\n",
        "\n",
        "2. El segon pas ser√† convertir les oracions en seq√º√®ncies de nombres enters usant el tokenitzador.\n",
        "\n",
        "3. El tercer pas ser√† guardar la longitud original de cada oraci√≥. Aix√≤ ens ser√† √∫til per evaluar el nostre model sense tenir en compte el padding.\n",
        "\n",
        "3. Finalment, per aconseguir que totes les seq√º√®ncies tinguen la mateixa longitud, fixarem la longitud segons la m√†xima trobada a l'entrenament i afegirem zeros a les oracions de menor longitud.\n",
        "\n",
        "Recordeu que podeu consultar com fer-ho a la documentaci√≥ de la llibrer√≠a:\n",
        "* <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\"> Tokenizer </a>\n",
        "* <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\"> Pad Sequences </a>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0zOvP3UI_CE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a622074-816c-486e-c950-37f2a8570ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 831\n",
            "Max sequence length (train): 46\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "\n",
        "# 1) Construir el vocabulari nom√©s amb les oracions de train\n",
        "tokenizer = Tokenizer(lower=False, filters='')\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "# 2) Convertir oracions a seq√º√®ncies d'√≠ndexs\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "val_sequences   = tokenizer.texts_to_sequences(val_sentences)\n",
        "test_sequences  = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "# 3) Longitud original abans del padding\n",
        "len_train_sequences = [len(seq) for seq in train_sequences]\n",
        "len_val_sequences   = [len(seq) for seq in val_sequences]\n",
        "len_test_sequences  = [len(seq) for seq in test_sequences]\n",
        "\n",
        "# Longitud m√†xima a partir del train\n",
        "max_sequence_length = max(len_train_sequences) if len_train_sequences else 0\n",
        "\n",
        "# 4) Padding i truncat post a la longitud m√†xima\n",
        "train_pad_sequences = pad_sequences(\n",
        "    train_sequences, maxlen=max_sequence_length, padding='post', truncating='post', value=0\n",
        ")\n",
        "val_pad_sequences = pad_sequences(\n",
        "    val_sequences, maxlen=max_sequence_length, padding='post', truncating='post', value=0\n",
        ")\n",
        "test_pad_sequences = pad_sequences(\n",
        "    test_sequences, maxlen=max_sequence_length, padding='post', truncating='post', value=0\n",
        ")\n",
        "\n",
        "# Mida de vocabulari\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "print(\"Max sequence length (train):\", max_sequence_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQPTc0CyOzLh",
        "outputId": "b06f7fb0-5d2b-47d3-b287-0804f464df51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 12,  69,   1,  38,   2,   9,  64, 415,  84,  17,  75,  16,  13,\n",
              "        64, 493,  16,   4,  36,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_pad_sequences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n55MNuHfMegM"
      },
      "source": [
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wNo-X61OyRc"
      },
      "source": [
        "Tal com vam fer a la primera part, aqu√≠ tamb√© hem de convertir les diferents classes d'entitats en vectors one-hot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD9_A1RJP1LZ"
      },
      "source": [
        "---\n",
        "\n",
        " <h1><a name=\"ex-four\"><center> ‚úè Exercici 4 ‚úè</a></h1>\n",
        "\n",
        "Per aconseguir-ho haureu de seguir els passos seg√ºents.\n",
        "\n",
        " 1. En primer lloc, haureu d'esbrinar quantes etiquetes diferents hi ha. Podeu prendre com a exemple la funci√≥ `count_unique_entities` per fer-ho. Tingueu en compte que haureu de modificar la funci√≥, ja que per exemple aquesta funci√≥ considera que `B-depart_time.time`, `I-depart_time.time`, `L-depart_time.time`, `U-depart_time.time` s√≥n la mateixa entitat. En aquest exercici, necessitarem comptar-les per separat. Tamb√© l'entitat O ha de ser considerada com una classe.\n",
        "\n",
        " 2. El segon pas ser√† codificar les diferents classes trobades en etiquetes num√®riques. Tingueu en compte que cada paraula de l'oraci√≥ t√© una etiqueta i, per tant, per a cada oraci√≥ tindrem una llista d'etiquetes. El *padding* el codificarem amb l'etiqueta corresponent a **O** (outside). Per ajudar-vos hem preparat el processament per a les etiquetes d'entrenament, intenteu comprendre el que es fa i aix√≠ repetir-ho per a la partici√≥ de validaci√≥ i test.\n",
        "\n",
        " 3. Finalment, haureu de convertir les diferents classes a vectors one-hot. Recordeu de nou que per a cada oraci√≥ tindrem una llista de vectors one-hot.\n",
        "\n",
        "\n",
        " Podeu consultar els apartats de la documentaci√≥:\n",
        " * <a href=https://www.tensorflow.org/guide/keras/understanding_masking_and_padding> Masking and Padding </a>\n",
        "\n",
        " * <a href=https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical> To Categorical </a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKO7Ps31ql4i",
        "outputId": "c4684832-42d7-44fb-a521-d7ca63734edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different entities: 120\n",
            "Unique entities: ['<pad>', 'O', 'B-fromloc.city_name', 'B-depart_time.time', 'I-depart_time.time', 'B-toloc.city_name', 'B-arrive_time.time', 'B-arrive_time.period_of_day', 'B-depart_date.day_name', 'B-depart_time.period_of_day', 'B-flight_time', 'I-flight_time', 'I-fromloc.city_name', 'B-cost_relative', 'B-round_trip', 'I-round_trip', 'B-fare_amount', 'I-fare_amount', 'B-depart_date.today_relative', 'I-toloc.city_name', 'B-city_name', 'B-stoploc.city_name', 'B-toloc.airport_code', 'B-depart_time.time_relative', 'B-class_type', 'I-class_type', 'B-depart_date.date_relative', 'B-airline_name', 'I-airline_name', 'B-arrive_time.time_relative', 'B-depart_time.start_time', 'I-depart_time.start_time', 'B-depart_time.end_time', 'I-depart_time.end_time', 'B-fromloc.airport_name', 'I-fromloc.airport_name', 'B-toloc.state_name', 'B-depart_date.day_number', 'I-depart_date.day_number', 'B-depart_date.month_name', 'B-mod', 'B-fare_basis_code', 'B-transport_type', 'B-flight_mod', 'I-cost_relative', 'B-arrive_date.month_name', 'B-arrive_date.day_number', 'B-meal', 'B-toloc.state_code', 'B-meal_description', 'B-return_date.month_name', 'B-return_date.day_number', 'B-airline_code', 'B-depart_time.period_mod', 'I-arrive_time.time', 'B-flight_stop', 'I-city_name', 'B-fromloc.airport_code', 'B-arrive_date.day_name', 'B-time', 'B-or', 'I-arrive_date.day_number', 'B-economy', 'I-economy', 'B-flight_number', 'B-arrive_time.period_mod', 'I-transport_type', 'B-flight_days', 'I-stoploc.city_name', 'B-toloc.airport_name', 'I-toloc.airport_name', 'B-state_code', 'I-flight_stop', 'B-arrive_time.start_time', 'B-arrive_time.end_time', 'I-arrive_time.end_time', 'B-fromloc.state_name', 'I-fromloc.state_name', 'B-arrive_date.date_relative', 'B-depart_date.year', 'B-return_date.date_relative', 'B-airport_code', 'B-aircraft_code', 'B-fromloc.state_code', 'B-connect', 'I-arrive_time.start_time', 'B-restriction_code', 'I-restriction_code', 'I-toloc.state_name', 'B-airport_name', 'I-airport_name', 'B-toloc.country_name', 'B-days_code', 'I-fare_basis_code', 'I-arrive_time.time_relative', 'I-arrive_time.period_of_day', 'I-depart_time.time_relative', 'B-day_name', 'B-period_of_day', 'I-depart_date.day_name', 'B-today_relative', 'B-stoploc.state_code', 'B-meal_code', 'I-meal_code', 'I-today_relative', 'I-flight_mod', 'B-state_name', 'B-stoploc.airport_name', 'B-arrive_date.today_relative', 'B-time_relative', 'I-time', 'B-return_time.period_of_day', 'I-return_date.day_number', 'I-depart_time.period_of_day', 'B-return_time.period_mod', 'I-depart_date.today_relative', 'I-mod', 'B-month_name', 'B-day_number', 'I-return_date.date_relative']\n",
            "labels to remove:   ['I-meal_description', 'B-return_date.today_relative', 'I-return_date.today_relative', 'I-return_date.today_relative', 'B-return_date.day_name']\n",
            "labels to remove:   ['B-return_date.day_name', 'I-flight_number', 'B-compartment', 'B-stoploc.airport_code', 'I-state_name', 'B-return_date.day_name', 'B-booking_class', 'B-flight']\n",
            "Shapes one-hot -> train: (4078, 46, 119) val: (897, 46, 119) test: (885, 46, 119)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1) Comptar entitats √∫niques de TRAIN (BIO/BILOU) i afegir <pad> al principi\n",
        "_TAG_RE = re.compile(r\"^(?:[BILU]-)?[A-Za-z_]+(?:\\.[A-Za-z_]+)*$|^O$\")\n",
        "\n",
        "def _clean_tag(t: str) -> str:\n",
        "    \"\"\"Elimina espais i cometes inicials/finals.\"\"\"\n",
        "    t = t.strip()\n",
        "    return re.sub(r'^[\"\\']+|[\"\\']+$', '', t)\n",
        "\n",
        "def _split_labels(maybe_str_or_list):\n",
        "    \"\"\"\n",
        "    Accepta:\n",
        "      - string amb etiquetes separades per espais: 'O B-foo I-foo'\n",
        "      - llista d'etiquetes: ['O','B-foo','I-foo']\n",
        "    Neteja i filtra etiquetes no v√†lides.\n",
        "    \"\"\"\n",
        "    if isinstance(maybe_str_or_list, str):\n",
        "        raw = maybe_str_or_list.strip().split()\n",
        "    else:\n",
        "        raw = list(maybe_str_or_list)\n",
        "\n",
        "    out = []\n",
        "    for tok in raw:\n",
        "        if not isinstance(tok, str) or not tok.strip():\n",
        "            continue\n",
        "        tag = _clean_tag(tok)\n",
        "        if _TAG_RE.match(tag):\n",
        "            out.append(tag)\n",
        "    return out\n",
        "\n",
        "def count_unique_entities_in_order(list_of_label_sentences):\n",
        "    \"\"\"\n",
        "    Retorna:\n",
        "      - nombre de classes + 1 (per <pad>)\n",
        "      - llista de classes (sense <pad>) en ordre d'aparici√≥ a TRAIN\n",
        "      - llista imprimible amb <pad> al principi\n",
        "    \"\"\"\n",
        "    seen = set()\n",
        "    classes = []\n",
        "    for sent in list_of_label_sentences:\n",
        "        for tag in _split_labels(sent):\n",
        "            if tag not in seen:\n",
        "                seen.add(tag)\n",
        "                classes.append(tag)\n",
        "    if 'O' not in seen:\n",
        "        classes.append('O')\n",
        "    printable = ['<pad>'] + classes\n",
        "    return len(printable), classes, printable\n",
        "\n",
        "# Variables existents:\n",
        "#   train_labels\n",
        "#   max_sequence_length\n",
        "#   train_pad_sequences, val_pad_sequences, test_pad_sequences\n",
        "\n",
        "num_unique_entities, classes, unique_entities_print = count_unique_entities_in_order(train_labels)\n",
        "print(\"Number of different entities:\", num_unique_entities)\n",
        "print(\"Unique entities:\", unique_entities_print)\n",
        "\n",
        "# 2) LabelEncoder amb classes de TRAIN (sense '<pad>') + padding amb 'O'\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(classes)\n",
        "o_ix = int(label_encoder.transform(['O'])[0])\n",
        "\n",
        "def labels_to_ids(list_of_label_sentences):\n",
        "    ids_per_sentence = []\n",
        "    for sent in list_of_label_sentences:\n",
        "        tags = _split_labels(sent)\n",
        "        ids_per_sentence.append(label_encoder.transform(tags))\n",
        "    return ids_per_sentence\n",
        "\n",
        "def pad_or_truncate_label_ids(list_of_label_id_sents, max_len, pad_value):\n",
        "    out = []\n",
        "    for ids in list_of_label_id_sents:\n",
        "        ids = list(ids)\n",
        "        if len(ids) >= max_len:\n",
        "            out.append(ids[:max_len])\n",
        "        else:\n",
        "            out.append(ids + [pad_value] * (max_len - len(ids)))\n",
        "    return np.array(out, dtype=np.int32)\n",
        "\n",
        "def remove_sentences(list_labels, list_sequences, allowed_set):\n",
        "    \"\"\"\n",
        "    Elimina oracions amb etiquetes no vistes a TRAIN.\n",
        "    Imprimeix 'labels to remove: [...]' amb duplicats i ordre d'aparici√≥.\n",
        "    \"\"\"\n",
        "    bad_idx = set()\n",
        "    labels_to_remove = []\n",
        "\n",
        "    for idx, raw in enumerate(list_labels):\n",
        "        tags = _split_labels(raw)\n",
        "        unknowns = [t for t in tags if t not in allowed_set]\n",
        "        if unknowns:\n",
        "            bad_idx.add(idx)\n",
        "            labels_to_remove.extend(unknowns)\n",
        "\n",
        "    kept_labels    = [l for i, l in enumerate(list_labels)    if i not in bad_idx]\n",
        "    kept_sequences = [s for i, s in enumerate(list_sequences) if i not in bad_idx]\n",
        "\n",
        "    if labels_to_remove:\n",
        "        print(\"labels to remove:  \", labels_to_remove)\n",
        "\n",
        "    return kept_labels, np.array(kept_sequences)\n",
        "\n",
        "# TRAIN\n",
        "train_numerical_labels = labels_to_ids(train_labels)\n",
        "train_pad_labels      = pad_or_truncate_label_ids(train_numerical_labels, max_sequence_length, o_ix)\n",
        "\n",
        "# VALIDATION\n",
        "_val_allowed = set(classes)\n",
        "val_labels,  val_pad_sequences  = remove_sentences(val_labels,  val_pad_sequences,  _val_allowed)\n",
        "val_numerical_labels  = labels_to_ids(val_labels)\n",
        "val_pad_labels        = pad_or_truncate_label_ids(val_numerical_labels,  max_sequence_length, o_ix)\n",
        "\n",
        "# TEST\n",
        "_test_allowed = set(classes)\n",
        "test_labels, test_pad_sequences = remove_sentences(test_labels, test_pad_sequences, _test_allowed)\n",
        "test_numerical_labels = labels_to_ids(test_labels)\n",
        "test_pad_labels       = pad_or_truncate_label_ids(test_numerical_labels, max_sequence_length, o_ix)\n",
        "\n",
        "# 3) One-hot per token. num_classes = len(classes) (sense '<pad>')\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_one_hot = to_categorical(train_pad_labels, num_classes=num_classes)\n",
        "val_labels_one_hot   = to_categorical(val_pad_labels,   num_classes=num_classes)\n",
        "test_labels_one_hot  = to_categorical(test_pad_labels,  num_classes=num_classes)\n",
        "\n",
        "try:\n",
        "    assert train_pad_sequences.shape[1] == train_pad_labels.shape[1] == max_sequence_length\n",
        "    assert val_pad_sequences.shape[1]   == val_pad_labels.shape[1]   == max_sequence_length\n",
        "    assert test_pad_sequences.shape[1]  == test_pad_labels.shape[1]  == max_sequence_length\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "print(\"Shapes one-hot ->\",\n",
        "      \"train:\", train_labels_one_hot.shape,\n",
        "      \"val:\",   val_labels_one_hot.shape,\n",
        "      \"test:\",  test_labels_one_hot.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "975GjI0tp7_9"
      },
      "source": [
        "<h1><a name=\"section-three\"> 3. Disseny del model i entrenament </a></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMY7LjpHv7GZ"
      },
      "source": [
        "---\n",
        "<h1><a name=\"ex-five\"><center> ‚úè Exercici 5 ‚úè</a></h1>\n",
        "\n",
        "De forma similar com f√©reu a la primera part de la pr√†ctica us demanem que dissenyeu l'arquitectura i entreneu el model. Podeu fer servir una arquitectura similar. Ara b√©, per capturar les depend√®ncies seq√ºencials podeu canviar la capa de GlobalMaxPooling1D per una LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8Ed4x77t_4d",
        "outputId": "b5ac0d3c-57a3-482b-f341-6f09bcd7777a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(187588,) [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118]\n"
          ]
        }
      ],
      "source": [
        "s = train_pad_labels.shape\n",
        "train_flat_labels = train_pad_labels.reshape(s[0]*s[1])\n",
        "train_unq_labels = np.unique(train_flat_labels)\n",
        "print(train_flat_labels.shape, train_unq_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMPaZzX4sdH4"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
        "                keras.layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = keras.layers.Dropout(rate)\n",
        "        self.dropout2 = keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "\n",
        "class TokenAndPositionEmbedding(keras.layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = keras.layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        maxlen = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        position_embeddings = self.pos_emb(positions)\n",
        "        token_embeddings = self.token_emb(inputs)\n",
        "        return token_embeddings + position_embeddings\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcWiSLm3nvdW",
        "outputId": "918000a9-91e9-4915-fb94-9f5de71b0c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.1546 - loss: 2.9033 - val_accuracy: 0.1913 - val_loss: 1.0332 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2028 - loss: 0.8483 - val_accuracy: 0.2067 - val_loss: 0.7214 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.2185 - loss: 0.5634 - val_accuracy: 0.2200 - val_loss: 0.5324 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2262 - loss: 0.3725 - val_accuracy: 0.2255 - val_loss: 0.4186 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2336 - loss: 0.2631 - val_accuracy: 0.2283 - val_loss: 0.3594 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2366 - loss: 0.1946 - val_accuracy: 0.2302 - val_loss: 0.3227 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2425 - loss: 0.1531 - val_accuracy: 0.2320 - val_loss: 0.3002 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2390 - loss: 0.1156 - val_accuracy: 0.2325 - val_loss: 0.2850 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2420 - loss: 0.1008 - val_accuracy: 0.2336 - val_loss: 0.2746 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2440 - loss: 0.0837 - val_accuracy: 0.2340 - val_loss: 0.2656 - learning_rate: 0.0010\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2267 - loss: 0.2652\n",
            "Test accuracy: 0.21\n",
            "preds.shape -> (885, 46, 120)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "# 1) Afegeix classe <pad> a les etiquetes (pad detectat pel 0 a les seq√º√®ncies d'entrada)\n",
        "old_num_classes = int(train_labels_one_hot.shape[-1])\n",
        "PAD_IX = old_num_classes\n",
        "num_classes = old_num_classes + 1\n",
        "\n",
        "def inject_pad_class(y_ids, x_pad_sequences, pad_ix):\n",
        "    \"\"\"Substitueix posicions de padding (tokens == 0) per la classe PAD a y.\"\"\"\n",
        "    y = y_ids.copy()\n",
        "    mask = (x_pad_sequences == 0)\n",
        "    y[mask] = pad_ix\n",
        "    return y\n",
        "\n",
        "train_y_ids_ext = inject_pad_class(train_pad_labels, train_pad_sequences, PAD_IX)\n",
        "val_y_ids_ext   = inject_pad_class(val_pad_labels,   val_pad_sequences,   PAD_IX)\n",
        "test_y_ids_ext  = inject_pad_class(test_pad_labels,  test_pad_sequences,  PAD_IX)\n",
        "\n",
        "# One-hot nou amb 120 classes (inclou <pad>)\n",
        "train_labels_one_hot = to_categorical(train_y_ids_ext, num_classes=num_classes)\n",
        "val_labels_one_hot   = to_categorical(val_y_ids_ext,   num_classes=num_classes)\n",
        "test_labels_one_hot  = to_categorical(test_y_ids_ext,  num_classes=num_classes)\n",
        "\n",
        "# Pesos per ignorar <pad> a la loss\n",
        "train_w = (train_y_ids_ext != PAD_IX).astype(\"float32\")\n",
        "val_w   = (val_y_ids_ext   != PAD_IX).astype(\"float32\")\n",
        "test_w  = (test_y_ids_ext  != PAD_IX).astype(\"float32\")\n",
        "\n",
        "# 2) Model (sortida de 120)\n",
        "embedding_dim = 128\n",
        "vocab_size = int(np.max(train_pad_sequences)) + 1\n",
        "\n",
        "model = Sequential([\n",
        "    keras.layers.Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        mask_zero=True,\n",
        "        input_length=train_pad_sequences.shape[1]\n",
        "    ),\n",
        "    keras.layers.LSTM(128, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(num_classes, activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# 3) Entrenament (sample_weight per no penalitzar <pad>)\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_pad_sequences,\n",
        "    y=train_labels_one_hot,\n",
        "    sample_weight=train_w,\n",
        "    validation_data=(val_pad_sequences, val_labels_one_hot, val_w),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 4) Avaluaci√≥ i predicci√≥\n",
        "loss, accuracy = model.evaluate(\n",
        "    test_pad_sequences, test_labels_one_hot, sample_weight=test_w, batch_size=batch_size, verbose=1\n",
        ")\n",
        "print(f\"Test accuracy: {accuracy:.2f}\")\n",
        "\n",
        "preds = model.predict(test_pad_sequences, batch_size=batch_size, verbose=0)\n",
        "print(\"preds.shape ->\", preds.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ts_03xMaADp",
        "outputId": "1d5d5d39-c06e-42b6-dc0b-a86facde8292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(test_pad_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cP_IiZFmFK8",
        "outputId": "d66b772a-870b-400e-8d06-b6cf59f1e6d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(885, 46, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxFoy2UBktFS"
      },
      "outputs": [],
      "source": [
        "def preds_to_index(preds, seq_lens):\n",
        "  '''\n",
        "  Turn predictions to numerical indexes, flatten the sentences and discard padding.\n",
        "  '''\n",
        "  idx_preds = []\n",
        "  for pred, seq_len in zip(preds,seq_lens):\n",
        "      for l in range(seq_len):\n",
        "        idx_preds.append(np.argmax(pred[l]))\n",
        "  return idx_preds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeVIzSA4NYgD"
      },
      "source": [
        "Com ja sabeu, NER es una tasca on les dades estan molt desbalancejades. La gran majoria de les nostres etiquetes ser√°n 'O' (outside). Es pot donar el cas on el model tingui una accuracy molt alta predint sempre 'O'.\n",
        "\n",
        "Per mesurar millor com de b√≥ √©s el nostre model, calcularem la F1 score per cada classe, aix√≠ com la mitjana (macro average). Quan prepareu el vostre document, heu de reportar aquesta mitjana com a m√®trica del vostre model, no l'acuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4DL7Tota13v",
        "outputId": "cdbcaf32-e547-476d-c7b5-746ca46ea4db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92        20\n",
            "           1       0.87      0.50      0.63        26\n",
            "           2       0.86      0.95      0.90        79\n",
            "           3       1.00      0.20      0.33         5\n",
            "           4       0.29      0.11      0.16        18\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       0.70      1.00      0.82         7\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.67      0.67      0.67         3\n",
            "          12       0.50      1.00      0.67         2\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       0.79      0.92      0.85        12\n",
            "          15       0.71      0.86      0.77        14\n",
            "          16       0.63      0.54      0.58        41\n",
            "          17       0.96      0.96      0.96        24\n",
            "          18       1.00      0.50      0.67         6\n",
            "          19       1.00      1.00      1.00        33\n",
            "          20       1.00      0.00      0.00         2\n",
            "          23       0.75      0.90      0.82        10\n",
            "          24       0.99      0.98      0.98       140\n",
            "          25       0.94      1.00      0.97        33\n",
            "          26       0.98      0.98      0.98        41\n",
            "          27       1.00      0.83      0.91         6\n",
            "          28       0.00      1.00      0.00         0\n",
            "          29       1.00      1.00      1.00         3\n",
            "          30       1.00      0.00      0.00         1\n",
            "          31       0.96      0.93      0.95        85\n",
            "          32       1.00      0.67      0.80         3\n",
            "          33       0.76      0.84      0.80        19\n",
            "          34       0.02      0.97      0.04        32\n",
            "          35       1.00      0.20      0.33         5\n",
            "          37       1.00      0.71      0.83        14\n",
            "          38       1.00      1.00      1.00         7\n",
            "          39       0.91      0.91      0.91        22\n",
            "          40       1.00      0.17      0.29         6\n",
            "          41       1.00      1.00      1.00        17\n",
            "          42       1.00      1.00      1.00         1\n",
            "          43       1.00      1.00      1.00         3\n",
            "          44       0.12      0.12      0.12         8\n",
            "          45       0.96      0.99      0.98       613\n",
            "          46       1.00      1.00      1.00        18\n",
            "          47       0.92      1.00      0.96        12\n",
            "          48       0.92      1.00      0.96        11\n",
            "          50       1.00      0.60      0.75         5\n",
            "          51       1.00      0.00      0.00         1\n",
            "          53       0.00      1.00      0.00         0\n",
            "          54       1.00      0.00      0.00         3\n",
            "          55       1.00      0.75      0.86         4\n",
            "          61       0.98      1.00      0.99        62\n",
            "          62       1.00      1.00      1.00         1\n",
            "          63       1.00      0.00      0.00         6\n",
            "          65       0.88      1.00      0.93         7\n",
            "          70       1.00      1.00      1.00         1\n",
            "          71       1.00      0.33      0.50         3\n",
            "          72       0.97      0.98      0.98       519\n",
            "          74       1.00      1.00      1.00        12\n",
            "          75       0.82      0.69      0.75        13\n",
            "          76       1.00      1.00      1.00        10\n",
            "          77       0.94      1.00      0.97        51\n",
            "          78       0.62      0.36      0.46        22\n",
            "          83       1.00      1.00      1.00         9\n",
            "          85       0.65      0.62      0.63        21\n",
            "          86       1.00      1.00      1.00        16\n",
            "          87       1.00      1.00      1.00         2\n",
            "          89       0.86      1.00      0.92         6\n",
            "          91       1.00      0.33      0.50         3\n",
            "          93       0.50      1.00      0.67         1\n",
            "          94       0.76      1.00      0.87        13\n",
            "          95       1.00      0.00      0.00         1\n",
            "          99       1.00      0.00      0.00         6\n",
            "         101       1.00      1.00      1.00         1\n",
            "         102       0.31      0.62      0.42         8\n",
            "         103       0.97      0.99      0.98       142\n",
            "         107       1.00      0.67      0.80         3\n",
            "         110       1.00      1.00      1.00        58\n",
            "         111       0.67      1.00      0.80         4\n",
            "         114       1.00      0.67      0.80         3\n",
            "         115       0.97      0.98      0.97       146\n",
            "         116       1.00      1.00      1.00         1\n",
            "         117       1.00      0.00      0.00         1\n",
            "         118       0.99      0.99      0.99      4855\n",
            "         119       1.00      0.00      0.00      1581\n",
            "\n",
            "    accuracy                           0.80      9010\n",
            "   macro avg       0.87      0.73      0.70      9010\n",
            "weighted avg       0.97      0.80      0.79      9010\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_labels_idx = preds_to_index(test_labels_one_hot,len_test_sequences)\n",
        "preds_idx = preds_to_index(preds, len_test_sequences)\n",
        "\n",
        "print(classification_report(test_labels_idx, preds_idx, zero_division=1.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VArxTPJgEaTx"
      },
      "source": [
        "A continuaci√≥ podeu veure algunes prediccions del model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S4H2EqYmiqs",
        "outputId": "d29560b5-3719-4152-e35d-9ee3c2b38118",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Sentence:  i would like to find a flight from charlotte to las vegas that makes a stop in st. louis\n",
            "Original label:   \"O O O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O O O O O B-stoploc.city_name I-stoploc.city_name\"\n",
            "Predicted label:  [np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('I-toloc.city_name'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-stoploc.city_name'), np.str_('I-stoploc.city_name'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n",
            "Sentence:  on april first i need a ticket from tacoma to san jose departing before 7 am\n",
            "Original label:   \"O B-depart_date.month_name B-depart_date.day_number O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-depart_time.time_relative B-depart_time.time I-depart_time.time\"\n",
            "Predicted label:  [np.str_('O'), np.str_('B-depart_date.month_name'), np.str_('B-depart_date.day_number'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('I-toloc.city_name'), np.str_('O'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time'), np.str_('I-depart_time.time'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n",
            "Sentence:  on april first i need a flight going from phoenix to san diego\n",
            "Original label:   \"O B-depart_date.month_name B-depart_date.day_number O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name\"\n",
            "Predicted label:  [np.str_('O'), np.str_('B-depart_date.month_name'), np.str_('B-depart_date.day_number'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('I-toloc.city_name'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n",
            "Sentence:  i would like a flight traveling one way from phoenix to san diego on april first\n",
            "Original label:   \"O O O O O O B-round_trip I-round_trip O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-depart_date.month_name B-depart_date.day_number\"\n",
            "Predicted label:  [np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-round_trip'), np.str_('I-round_trip'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('I-toloc.city_name'), np.str_('O'), np.str_('B-depart_date.month_name'), np.str_('B-depart_date.day_number'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n",
            "Sentence:  i would like a flight from orlando to salt lake city for april first on delta airlines\n",
            "Original label:   \"O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name I-toloc.city_name O B-depart_date.month_name B-depart_date.day_number O B-airline_name I-airline_name\"\n",
            "Predicted label:  [np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('I-toloc.city_name'), np.str_('I-toloc.city_name'), np.str_('O'), np.str_('B-depart_date.month_name'), np.str_('B-depart_date.day_number'), np.str_('O'), np.str_('B-airline_name'), np.str_('I-airline_name'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n",
            "Sentence:  i need a flight from toronto to newark one way leaving wednesday evening or thursday morning\n",
            "Original label:   \"O O O O O B-fromloc.city_name O B-toloc.city_name B-round_trip I-round_trip O B-depart_date.day_name B-depart_time.period_of_day O B-depart_date.day_name B-depart_time.period_of_day\"\n",
            "Predicted label:  [np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('B-round_trip'), np.str_('I-round_trip'), np.str_('O'), np.str_('B-depart_date.day_name'), np.str_('B-depart_time.period_of_day'), np.str_('B-or'), np.str_('B-depart_date.day_name'), np.str_('B-depart_time.period_of_day'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n",
            "Sentence:  monday morning i would like to fly from columbus to indianapolis\n",
            "Original label:   \"B-depart_date.day_name B-depart_time.period_of_day O O O O O O B-fromloc.city_name O B-toloc.city_name\"\n",
            "Predicted label:  [np.str_('B-depart_date.day_name'), np.str_('B-depart_time.period_of_day'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n",
            "Sentence:  on wednesday april sixth i would like to fly from long beach to columbus after 3 pm\n",
            "Original label:   \"O B-depart_date.day_name B-depart_date.month_name B-depart_date.day_number O O O O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name B-depart_time.time_relative B-depart_time.time I-depart_time.time\"\n",
            "Predicted label:  [np.str_('O'), np.str_('B-depart_date.day_name'), np.str_('B-depart_date.month_name'), np.str_('B-depart_date.day_number'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('I-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time'), np.str_('I-depart_time.time'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n",
            "Sentence:  after 12 pm on wednesday april sixth i would like to fly from long beach to columbus\n",
            "Original label:   \"B-depart_time.time_relative B-depart_time.time I-depart_time.time O B-depart_date.day_name B-depart_date.month_name B-depart_date.day_number O O O O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name\"\n",
            "Predicted label:  [np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('I-depart_time.time'), np.str_('O'), np.str_('B-depart_date.day_name'), np.str_('B-depart_date.month_name'), np.str_('B-depart_date.day_number'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('I-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n",
            "Sentence:  are there any flights from long beach to columbus on wednesday april sixth\n",
            "Original label:   \"O O O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name O B-depart_date.day_name B-depart_date.month_name B-depart_date.day_number\"\n",
            "Predicted label:  [np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-fromloc.city_name'), np.str_('I-fromloc.city_name'), np.str_('O'), np.str_('B-toloc.city_name'), np.str_('O'), np.str_('B-depart_date.day_name'), np.str_('B-depart_date.month_name'), np.str_('B-depart_date.day_number'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative'), np.str_('B-depart_time.time_relative')]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "probs = model.predict(test_pad_sequences)\n",
        "_predicted_labels = np.argmax(probs, axis=2)\n",
        "\n",
        "predicted_labels = [list(label_encoder.inverse_transform(label)) for label in _predicted_labels]\n",
        "\n",
        "for i in range(0, 10):\n",
        "    print('Sentence: ', test_sentences[i])\n",
        "    print('Original label: ', test_labels[i])\n",
        "    print('Predicted label: ', predicted_labels[i])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65EQLymROmPX"
      },
      "source": [
        "---\n",
        "\n",
        " <h1><a name=\"ex-six\"><center> ‚úè Exercici 6 ‚úè </a></h1>\n",
        "\n",
        "Modifiqueu els seg√ºents par√†metres del model anterior i analitzeu com afecten a la seva *accuracy*:\n",
        "\n",
        " 1. **Mida dels Embeddings.** Proveu diferents mides d'*Embeddings* i observeu com canvia l'*accuracy* del model. Heu d'explicar les vostres conclusions.\n",
        "\n",
        " 2. **Xarxes Convolucionals.** Afegiu capes convolucionals al vostre model. Expliqueu amb detall els valors que heu provat i la vostra motivaci√≥ a l'hora d'escollir-los. Recordeu, que tamb√© podeu provar diferents configuracions de *pooling*.\n",
        "\n",
        " 3. **Xarxes Recurrents.**  Afegiu capes recurrents al vostre model (LSTM, GRU). Expliqueu amb detall els valors que heu provat i la vostra motivaci√≥.\n",
        "\n",
        " 4. ** Transformer** Afegiu blocs de Transformer al vostre model. Expliqueu amb detall els valors que heu provat i la vostra motivaci√≥.\n",
        "\n",
        " 5. **Regularitzaci√≥.** Quan proveu configuracions amb m√©s par√†metres veureu que el model comen√ßa a tenir *overfitting* molt prompte durant l'entrenament. Afegiu *Dropout* al vostre model. Heu d'explicar la vostra decisi√≥ de valors i de posici√≥ dins de la xarxa.\n",
        "\n",
        "\n",
        " 6. **Balancejat de les classes.** Si analitzeu el dataset, veureu que la freq√º√®ncia de les classes est√† molt desbalancejada. Keras us permet afegir un pes per a cada classe a l'hora de calcular la loss (Mireu el par√†metre \"class_weigth\" a la documentaci√≥ https://keras.io/api/models/model_training_apis/). Calculeu un pes per a cada classe i afegiu-lo al m√®tode fit del vostre model.\n",
        "\n",
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. **Mida dels Embeddings.** Proveu diferents mides d'*Embeddings* i observeu com canvia l'*accuracy* del model. Heu d'explicar les vostres conclusions."
      ],
      "metadata": {
        "id": "0zfAk0g5rUlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# Helpers\n",
        "def preds_to_index(preds, seq_lens):\n",
        "    \"\"\"Converteix probabilitats en √≠ndexs (argmax) i descarta padding segons la longitud real.\"\"\"\n",
        "    idx_preds = []\n",
        "    for pred, seq_len in zip(preds, seq_lens):\n",
        "        for l in range(seq_len):\n",
        "            idx_preds.append(int(np.argmax(pred[l])))\n",
        "    return idx_preds\n",
        "\n",
        "def final_three_metrics(y_true_idx, y_pred_idx):\n",
        "    \"\"\"Retorna accuracy, macro(avg) i weighted(avg).\"\"\"\n",
        "    acc = accuracy_score(y_true_idx, y_pred_idx)\n",
        "    mP, mR, mF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"macro\", zero_division=1.0\n",
        "    )\n",
        "    wP, wR, wF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"weighted\", zero_division=1.0\n",
        "    )\n",
        "    return {\n",
        "        \"accuracy\": float(acc),\n",
        "        \"macro_precision\": float(mP),\n",
        "        \"macro_recall\": float(mR),\n",
        "        \"macro_f1\": float(mF1),\n",
        "        \"weighted_precision\": float(wP),\n",
        "        \"weighted_recall\": float(wR),\n",
        "        \"weighted_f1\": float(wF1),\n",
        "        \"support_total\": int(len(y_true_idx)),\n",
        "    }\n",
        "\n",
        "def run_embeddings_and_print_table(\n",
        "    embed_dims=(32, 64, 128, 256, 512, 1024, 2048, 4096),\n",
        "    lstm_units=128,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    print_epoch_logs=True\n",
        "):\n",
        "    \"\"\"Entrena per a cada embedding_dim i imprimeix una taula amb m√®triques finals.\"\"\"\n",
        "    results = []\n",
        "    resumen_por_emb = {}\n",
        "\n",
        "    vocab_size = int(np.max(train_pad_sequences)) + 1\n",
        "    max_len    = int(train_pad_sequences.shape[1])\n",
        "    num_classes = int(train_labels_one_hot.shape[-1])\n",
        "\n",
        "    for emb in embed_dims:\n",
        "        print(\"\\n\" + \"=\"*90)\n",
        "        print(f\"Entrenando con embedding_dim = {emb}\")\n",
        "        print(\"=\"*90)\n",
        "        tf.keras.backend.clear_session()\n",
        "        start = time.time()\n",
        "\n",
        "        model = Sequential([\n",
        "            keras.layers.Embedding(\n",
        "                input_dim=vocab_size,\n",
        "                output_dim=emb,\n",
        "                mask_zero=True,\n",
        "                input_length=max_len\n",
        "            ),\n",
        "            keras.layers.LSTM(lstm_units, return_sequences=True),\n",
        "            keras.layers.TimeDistributed(\n",
        "                keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "        callbacks = [\n",
        "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "            keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2),\n",
        "        ]\n",
        "\n",
        "        history = model.fit(\n",
        "            x=train_pad_sequences,\n",
        "            y=train_labels_one_hot,\n",
        "            sample_weight=train_w,  # ignora <pad> a la loss\n",
        "            validation_data=(val_pad_sequences, val_labels_one_hot, val_w),\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1 if print_epoch_logs else 0\n",
        "        )\n",
        "\n",
        "        preds = model.predict(test_pad_sequences, batch_size=batch_size, verbose=0)\n",
        "        y_true_idx = preds_to_index(test_labels_one_hot, len_test_sequences)\n",
        "        y_pred_idx = preds_to_index(preds,                len_test_sequences)\n",
        "\n",
        "        final3 = final_three_metrics(y_true_idx, y_pred_idx)\n",
        "        resumen_por_emb[emb] = final3\n",
        "\n",
        "        results.append({\n",
        "            \"embedding_dim\": emb,\n",
        "            \"accuracy\": final3[\"accuracy\"],\n",
        "            \"macro_precision\": final3[\"macro_precision\"],\n",
        "            \"macro_recall\": final3[\"macro_recall\"],\n",
        "            \"macro_f1\": final3[\"macro_f1\"],\n",
        "            \"weighted_precision\": final3[\"weighted_precision\"],\n",
        "            \"weighted_recall\": final3[\"weighted_recall\"],\n",
        "            \"weighted_f1\": final3[\"weighted_f1\"],\n",
        "            \"support_total\": final3[\"support_total\"],\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results).sort_values(\"embedding_dim\")\n",
        "    cols = [\n",
        "        \"embedding_dim\",\n",
        "        \"accuracy\",\n",
        "        \"macro_precision\", \"macro_recall\", \"macro_f1\",\n",
        "        \"weighted_precision\", \"weighted_recall\", \"weighted_f1\",\n",
        "        \"support_total\"\n",
        "    ]\n",
        "    df = df[cols]\n",
        "    print(\"\\nResumen por tama√±o de embedding (los tres del final):\")\n",
        "    print(df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
        "\n",
        "    return df, resumen_por_emb\n",
        "\n",
        "tabla_final, resumen_por_emb = run_embeddings_and_print_table(\n",
        "    embed_dims=(32, 64, 128, 256, 512, 1024, 2048, 4096),\n",
        "    lstm_units=128,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    print_epoch_logs=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul1sUiz6rYwk",
        "outputId": "2eee0d9d-34dd-4316-e9c6-dcab63370c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "Entrenando con embedding_dim = 32\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.1496 - loss: 3.3110 - val_accuracy: 0.1776 - val_loss: 1.3482 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1901 - loss: 1.1855 - val_accuracy: 0.1906 - val_loss: 1.0178 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.1988 - loss: 0.8951 - val_accuracy: 0.1974 - val_loss: 0.8794 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2061 - loss: 0.7396 - val_accuracy: 0.2032 - val_loss: 0.7772 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2118 - loss: 0.6164 - val_accuracy: 0.2074 - val_loss: 0.7010 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.2151 - loss: 0.5345 - val_accuracy: 0.2119 - val_loss: 0.6408 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.2183 - loss: 0.4525 - val_accuracy: 0.2165 - val_loss: 0.5794 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2224 - loss: 0.3844 - val_accuracy: 0.2205 - val_loss: 0.5227 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2304 - loss: 0.3234 - val_accuracy: 0.2232 - val_loss: 0.4854 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2308 - loss: 0.2739 - val_accuracy: 0.2254 - val_loss: 0.4488 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando con embedding_dim = 64\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.1480 - loss: 3.1516 - val_accuracy: 0.1807 - val_loss: 1.2040 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1914 - loss: 1.0398 - val_accuracy: 0.1956 - val_loss: 0.8982 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2061 - loss: 0.7464 - val_accuracy: 0.2058 - val_loss: 0.7276 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2131 - loss: 0.5666 - val_accuracy: 0.2146 - val_loss: 0.5992 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2257 - loss: 0.4314 - val_accuracy: 0.2216 - val_loss: 0.4994 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2277 - loss: 0.3328 - val_accuracy: 0.2251 - val_loss: 0.4338 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.2331 - loss: 0.2532 - val_accuracy: 0.2274 - val_loss: 0.3877 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2378 - loss: 0.2014 - val_accuracy: 0.2299 - val_loss: 0.3575 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2397 - loss: 0.1642 - val_accuracy: 0.2313 - val_loss: 0.3392 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2401 - loss: 0.1353 - val_accuracy: 0.2326 - val_loss: 0.3179 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando con embedding_dim = 128\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.1521 - loss: 2.9628 - val_accuracy: 0.1877 - val_loss: 1.1053 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1954 - loss: 0.9377 - val_accuracy: 0.2040 - val_loss: 0.7522 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2134 - loss: 0.5733 - val_accuracy: 0.2190 - val_loss: 0.5402 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2285 - loss: 0.3918 - val_accuracy: 0.2248 - val_loss: 0.4222 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2349 - loss: 0.2638 - val_accuracy: 0.2284 - val_loss: 0.3615 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2346 - loss: 0.2002 - val_accuracy: 0.2302 - val_loss: 0.3257 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.2380 - loss: 0.1543 - val_accuracy: 0.2321 - val_loss: 0.2976 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2417 - loss: 0.1234 - val_accuracy: 0.2330 - val_loss: 0.2838 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2434 - loss: 0.0921 - val_accuracy: 0.2338 - val_loss: 0.2700 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2455 - loss: 0.0800 - val_accuracy: 0.2345 - val_loss: 0.2642 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando con embedding_dim = 256\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1558 - loss: 2.7379 - val_accuracy: 0.1954 - val_loss: 0.9541 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2068 - loss: 0.7520 - val_accuracy: 0.2166 - val_loss: 0.5935 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2269 - loss: 0.4322 - val_accuracy: 0.2249 - val_loss: 0.4154 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2366 - loss: 0.2542 - val_accuracy: 0.2291 - val_loss: 0.3402 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2395 - loss: 0.1852 - val_accuracy: 0.2307 - val_loss: 0.3046 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2404 - loss: 0.1271 - val_accuracy: 0.2330 - val_loss: 0.2772 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2450 - loss: 0.0944 - val_accuracy: 0.2339 - val_loss: 0.2619 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2436 - loss: 0.0773 - val_accuracy: 0.2341 - val_loss: 0.2577 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2458 - loss: 0.0640 - val_accuracy: 0.2345 - val_loss: 0.2545 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2449 - loss: 0.0540 - val_accuracy: 0.2349 - val_loss: 0.2490 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando con embedding_dim = 512\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.1605 - loss: 2.5418 - val_accuracy: 0.1997 - val_loss: 0.7999 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2159 - loss: 0.6044 - val_accuracy: 0.2243 - val_loss: 0.4351 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2357 - loss: 0.2800 - val_accuracy: 0.2296 - val_loss: 0.3230 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2431 - loss: 0.1654 - val_accuracy: 0.2320 - val_loss: 0.2738 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2431 - loss: 0.1158 - val_accuracy: 0.2334 - val_loss: 0.2473 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2404 - loss: 0.0821 - val_accuracy: 0.2343 - val_loss: 0.2344 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2463 - loss: 0.0614 - val_accuracy: 0.2345 - val_loss: 0.2291 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2459 - loss: 0.0490 - val_accuracy: 0.2347 - val_loss: 0.2281 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2475 - loss: 0.0388 - val_accuracy: 0.2348 - val_loss: 0.2310 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2459 - loss: 0.0340 - val_accuracy: 0.2352 - val_loss: 0.2262 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando con embedding_dim = 1024\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1662 - loss: 2.3016 - val_accuracy: 0.2141 - val_loss: 0.6574 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.2270 - loss: 0.4687 - val_accuracy: 0.2272 - val_loss: 0.3689 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2354 - loss: 0.2255 - val_accuracy: 0.2310 - val_loss: 0.2860 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2394 - loss: 0.1314 - val_accuracy: 0.2324 - val_loss: 0.2519 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2437 - loss: 0.0903 - val_accuracy: 0.2336 - val_loss: 0.2358 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2473 - loss: 0.0651 - val_accuracy: 0.2348 - val_loss: 0.2268 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2437 - loss: 0.0539 - val_accuracy: 0.2351 - val_loss: 0.2228 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2444 - loss: 0.0424 - val_accuracy: 0.2349 - val_loss: 0.2268 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2480 - loss: 0.0375 - val_accuracy: 0.2353 - val_loss: 0.2245 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2448 - loss: 0.0270 - val_accuracy: 0.2355 - val_loss: 0.2228 - learning_rate: 5.0000e-04\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando con embedding_dim = 2048\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.1715 - loss: 2.0831 - val_accuracy: 0.2202 - val_loss: 0.5364 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2306 - loss: 0.3648 - val_accuracy: 0.2294 - val_loss: 0.3204 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2383 - loss: 0.1744 - val_accuracy: 0.2325 - val_loss: 0.2599 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2421 - loss: 0.1081 - val_accuracy: 0.2336 - val_loss: 0.2376 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2447 - loss: 0.0688 - val_accuracy: 0.2342 - val_loss: 0.2276 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2461 - loss: 0.0502 - val_accuracy: 0.2347 - val_loss: 0.2219 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2456 - loss: 0.0431 - val_accuracy: 0.2353 - val_loss: 0.2213 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2458 - loss: 0.0371 - val_accuracy: 0.2353 - val_loss: 0.2211 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2463 - loss: 0.0272 - val_accuracy: 0.2353 - val_loss: 0.2258 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2434 - loss: 0.0225 - val_accuracy: 0.2352 - val_loss: 0.2294 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando con embedding_dim = 4096\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.1739 - loss: 1.8853 - val_accuracy: 0.2226 - val_loss: 0.4369 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2358 - loss: 0.2815 - val_accuracy: 0.2309 - val_loss: 0.2817 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2392 - loss: 0.1396 - val_accuracy: 0.2329 - val_loss: 0.2373 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2421 - loss: 0.0851 - val_accuracy: 0.2332 - val_loss: 0.2312 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2423 - loss: 0.0637 - val_accuracy: 0.2344 - val_loss: 0.2165 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.2445 - loss: 0.0475 - val_accuracy: 0.2347 - val_loss: 0.2166 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2456 - loss: 0.0383 - val_accuracy: 0.2349 - val_loss: 0.2149 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2446 - loss: 0.0318 - val_accuracy: 0.2352 - val_loss: 0.2155 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2490 - loss: 0.0247 - val_accuracy: 0.2354 - val_loss: 0.2166 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.2460 - loss: 0.0193 - val_accuracy: 0.2356 - val_loss: 0.2168 - learning_rate: 5.0000e-04\n",
            "\n",
            "Resumen por tama√±o de embedding (los tres del final):\n",
            " embedding_dim  accuracy  macro_precision  macro_recall  macro_f1  weighted_precision  weighted_recall  weighted_f1  support_total\n",
            "            32    0.7744           0.8144        0.3827    0.3394              0.9527           0.7744       0.7623           9010\n",
            "            64    0.7928           0.8177        0.5879    0.5637              0.9660           0.7928       0.7855           9010\n",
            "           128    0.8008           0.8314        0.7015    0.6572              0.9713           0.8008       0.7947           9010\n",
            "           256    0.8022           0.8438        0.7555    0.7158              0.9759           0.8022       0.7981           9010\n",
            "           512    0.8051           0.9016        0.7884    0.7693              0.9793           0.8051       0.8013           9010\n",
            "          1024    0.8041           0.8708        0.7497    0.7096              0.9791           0.8041       0.8009           9010\n",
            "          2048    0.8058           0.9050        0.7904    0.7699              0.9814           0.8058       0.8035           9010\n",
            "          4096    0.8039           0.9093        0.7578    0.7448              0.9785           0.8039       0.8000           9010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Xarxes Convolucionals.\n",
        "Afegiu capes convolucionals al vostre model. Expliqueu amb detall els valors que heu provat i la vostra motivaci√≥ a l'hora d'escollir-los. Recordeu, que tamb√© podeu provar diferents configuracions de pooling."
      ],
      "metadata": {
        "id": "RDM6NaI-zkrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import (Embedding, Conv1D, Dropout, MaxPooling1D,\n",
        "                                     AveragePooling1D, UpSampling1D, Cropping1D,\n",
        "                                     Concatenate)\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# -----------------------------\n",
        "# Utilitats\n",
        "# -----------------------------\n",
        "def preds_to_index(preds, seq_lens):\n",
        "    \"\"\"Converteix probabilitats en √≠ndexs (argmax) i descarta el padding segons la longitud real.\"\"\"\n",
        "    idx_preds = []\n",
        "    for pred, seq_len in zip(preds, seq_lens):\n",
        "        for l in range(seq_len):\n",
        "            idx_preds.append(int(np.argmax(pred[l])))\n",
        "    return idx_preds\n",
        "\n",
        "def final_three_metrics(y_true_idx, y_pred_idx):\n",
        "    \"\"\"Retorna accuracy, macro(avg) i weighted(avg).\"\"\"\n",
        "    acc = accuracy_score(y_true_idx, y_pred_idx)\n",
        "    mP, mR, mF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"macro\", zero_division=1.0\n",
        "    )\n",
        "    wP, wR, wF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"weighted\", zero_division=1.0\n",
        "    )\n",
        "    return {\n",
        "        \"accuracy\": float(acc),\n",
        "        \"macro_precision\": float(mP),\n",
        "        \"macro_recall\": float(mR),\n",
        "        \"macro_f1\": float(mF1),\n",
        "        \"weighted_precision\": float(wP),\n",
        "        \"weighted_recall\": float(wR),\n",
        "        \"weighted_f1\": float(wF1),\n",
        "        \"support_total\": int(len(y_true_idx)),\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# Construcci√≥ de models CNN per token\n",
        "# -----------------------------\n",
        "embedding_dim = 256\n",
        "vocab_size = int(np.max(train_pad_sequences)) + 1\n",
        "max_len = int(train_pad_sequences.shape[1])\n",
        "num_classes = int(train_labels_one_hot.shape[-1])\n",
        "\n",
        "def build_conv_token(kernel_size=5, filters=128, dropout=0.2):\n",
        "    \"\"\"Conv1D per token (sense pooling), mant√© la longitud i dona sortida per timestep.\"\"\"\n",
        "    inp = keras.Input(shape=(max_len,), dtype=\"int32\")\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                  input_length=max_len, mask_zero=False)(inp)\n",
        "    x = Conv1D(filters=filters, kernel_size=kernel_size,\n",
        "               padding=\"same\", activation=\"relu\")(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    out = Conv1D(filters=num_classes, kernel_size=1,\n",
        "                 padding=\"same\", activation=\"softmax\")(x)\n",
        "    model = keras.Model(inp, out)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def build_conv_pool_token(kernel_size=5, filters=128, pool_type=\"max\",\n",
        "                          pool_size=2, dropout=0.2):\n",
        "    \"\"\"Conv1D + pooling + UpSampling + Cropping per mantenir la longitud.\"\"\"\n",
        "    inp = keras.Input(shape=(max_len,), dtype=\"int32\")\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                  input_length=max_len, mask_zero=False)(inp)\n",
        "    x = Conv1D(filters=filters, kernel_size=kernel_size,\n",
        "               padding=\"same\", activation=\"relu\")(x)\n",
        "    if pool_type == \"max\":\n",
        "        x = MaxPooling1D(pool_size=pool_size, padding=\"same\")(x)\n",
        "    elif pool_type == \"avg\":\n",
        "        x = AveragePooling1D(pool_size=pool_size, padding=\"same\")(x)\n",
        "    else:\n",
        "        raise ValueError(\"pool_type ha de ser 'max' o 'avg'\")\n",
        "    x = UpSampling1D(size=pool_size)(x)\n",
        "    extra = (pool_size - (max_len % pool_size)) % pool_size\n",
        "    if extra > 0:\n",
        "        x = Cropping1D(cropping=(0, extra))(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    out = Conv1D(filters=num_classes, kernel_size=1,\n",
        "                 padding=\"same\", activation=\"softmax\")(x)\n",
        "    model = keras.Model(inp, out)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def build_textcnn_token(kernels=(3, 4, 5), filters=96, dropout=0.2):\n",
        "    \"\"\"TextCNN per token amb branques paral¬∑leles i concatenaci√≥ de canals.\"\"\"\n",
        "    inp = keras.Input(shape=(max_len,), dtype=\"int32\")\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                  input_length=max_len, mask_zero=False)(inp)\n",
        "    branches = []\n",
        "    for k in kernels:\n",
        "        c = Conv1D(filters=filters, kernel_size=k, padding=\"same\", activation=\"relu\")(x)\n",
        "        branches.append(c)\n",
        "    if len(branches) > 1:\n",
        "        x = Concatenate(axis=-1)(branches)\n",
        "    else:\n",
        "        x = branches[0]\n",
        "    x = Dropout(dropout)(x)\n",
        "    out = Conv1D(filters=num_classes, kernel_size=1,\n",
        "                 padding=\"same\", activation=\"softmax\")(x)\n",
        "    model = keras.Model(inp, out)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# -----------------------------\n",
        "# Experiments CNN\n",
        "# -----------------------------\n",
        "experiments = [\n",
        "    (\"conv_k3_nopool\",        build_conv_token(kernel_size=3, filters=128)),\n",
        "    (\"conv_k5_nopool\",        build_conv_token(kernel_size=5, filters=128)),\n",
        "    (\"conv_k7_nopool\",        build_conv_token(kernel_size=7, filters=128)),\n",
        "    (\"conv_k5_maxpool_up2\",   build_conv_pool_token(kernel_size=5, filters=128, pool_type=\"max\", pool_size=2)),\n",
        "    (\"conv_k5_avgpool_up2\",   build_conv_pool_token(kernel_size=5, filters=128, pool_type=\"avg\", pool_size=2)),\n",
        "    (\"textcnn_k345\",          build_textcnn_token(kernels=(3, 4, 5), filters=64)),\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# Entrenament i taula final\n",
        "# -----------------------------\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2),\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for name, model in experiments:\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"Entrenando {name}  (embedding_dim=512)\")\n",
        "    print(\"=\"*90)\n",
        "    hist = model.fit(\n",
        "        x=train_pad_sequences,\n",
        "        y=train_labels_one_hot,\n",
        "        sample_weight=train_w,  # ignora <pad>\n",
        "        validation_data=(val_pad_sequences, val_labels_one_hot, val_w),\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    preds = model.predict(test_pad_sequences, batch_size=batch_size, verbose=0)\n",
        "    y_true_idx = preds_to_index(test_labels_one_hot, len_test_sequences)\n",
        "    y_pred_idx = preds_to_index(preds,                len_test_sequences)\n",
        "    met = final_three_metrics(y_true_idx, y_pred_idx)\n",
        "\n",
        "    rows.append({\n",
        "        \"model\": name,\n",
        "        \"accuracy\": met[\"accuracy\"],\n",
        "        \"macro_precision\": met[\"macro_precision\"],\n",
        "        \"macro_recall\": met[\"macro_recall\"],\n",
        "        \"macro_f1\": met[\"macro_f1\"],\n",
        "        \"weighted_precision\": met[\"weighted_precision\"],\n",
        "        \"weighted_recall\": met[\"weighted_recall\"],\n",
        "        \"weighted_f1\": met[\"weighted_f1\"],\n",
        "        \"support_total\": met[\"support_total\"],\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df = df[[\n",
        "    \"model\",\n",
        "    \"accuracy\",\n",
        "    \"macro_precision\", \"macro_recall\", \"macro_f1\",\n",
        "    \"weighted_precision\", \"weighted_recall\", \"weighted_f1\",\n",
        "    \"support_total\"\n",
        "]].sort_values(\"model\")\n",
        "\n",
        "print(\"\\nResumen CNN (embedding=256):\")\n",
        "print(df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohEndr0rzodK",
        "outputId": "d15195b8-98f0-457c-f817-c0b69d48f0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "Entrenando conv_k3_nopool  (embedding_dim=512)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.1744 - loss: 0.6389 - val_accuracy: 0.2198 - val_loss: 0.1326 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2285 - loss: 0.0879 - val_accuracy: 0.2269 - val_loss: 0.0975 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2342 - loss: 0.0520 - val_accuracy: 0.2290 - val_loss: 0.0889 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2370 - loss: 0.0372 - val_accuracy: 0.2300 - val_loss: 0.0855 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2381 - loss: 0.0304 - val_accuracy: 0.2307 - val_loss: 0.0839 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2390 - loss: 0.0263 - val_accuracy: 0.2311 - val_loss: 0.0842 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2395 - loss: 0.0236 - val_accuracy: 0.2310 - val_loss: 0.0848 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2399 - loss: 0.0214 - val_accuracy: 0.2311 - val_loss: 0.0846 - learning_rate: 5.0000e-04\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando conv_k5_nopool  (embedding_dim=512)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.1735 - loss: 0.6060 - val_accuracy: 0.2191 - val_loss: 0.1388 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2282 - loss: 0.0911 - val_accuracy: 0.2283 - val_loss: 0.0921 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2360 - loss: 0.0458 - val_accuracy: 0.2313 - val_loss: 0.0810 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2395 - loss: 0.0296 - val_accuracy: 0.2323 - val_loss: 0.0773 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2411 - loss: 0.0219 - val_accuracy: 0.2330 - val_loss: 0.0761 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2421 - loss: 0.0176 - val_accuracy: 0.2334 - val_loss: 0.0761 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2425 - loss: 0.0151 - val_accuracy: 0.2335 - val_loss: 0.0766 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2429 - loss: 0.0128 - val_accuracy: 0.2338 - val_loss: 0.0771 - learning_rate: 5.0000e-04\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando conv_k7_nopool  (embedding_dim=512)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.1682 - loss: 0.5811 - val_accuracy: 0.2161 - val_loss: 0.1478 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2265 - loss: 0.0986 - val_accuracy: 0.2283 - val_loss: 0.0931 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2364 - loss: 0.0470 - val_accuracy: 0.2319 - val_loss: 0.0800 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2400 - loss: 0.0288 - val_accuracy: 0.2334 - val_loss: 0.0753 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2419 - loss: 0.0199 - val_accuracy: 0.2339 - val_loss: 0.0743 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2426 - loss: 0.0157 - val_accuracy: 0.2341 - val_loss: 0.0747 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2434 - loss: 0.0125 - val_accuracy: 0.2342 - val_loss: 0.0756 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2440 - loss: 0.0102 - val_accuracy: 0.2344 - val_loss: 0.0761 - learning_rate: 5.0000e-04\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando conv_k5_maxpool_up2  (embedding_dim=512)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.1483 - loss: 0.6468 - val_accuracy: 0.1688 - val_loss: 0.2378 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1733 - loss: 0.2167 - val_accuracy: 0.1733 - val_loss: 0.1687 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1770 - loss: 0.1618 - val_accuracy: 0.1747 - val_loss: 0.1467 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1782 - loss: 0.1399 - val_accuracy: 0.1750 - val_loss: 0.1358 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1782 - loss: 0.1292 - val_accuracy: 0.1756 - val_loss: 0.1308 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1794 - loss: 0.1216 - val_accuracy: 0.1756 - val_loss: 0.1277 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1796 - loss: 0.1176 - val_accuracy: 0.1756 - val_loss: 0.1260 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1795 - loss: 0.1141 - val_accuracy: 0.1758 - val_loss: 0.1242 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1801 - loss: 0.1115 - val_accuracy: 0.1756 - val_loss: 0.1235 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1807 - loss: 0.1101 - val_accuracy: 0.1756 - val_loss: 0.1233 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando conv_k5_avgpool_up2  (embedding_dim=512)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.1491 - loss: 0.6531 - val_accuracy: 0.1684 - val_loss: 0.2449 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1716 - loss: 0.2256 - val_accuracy: 0.1725 - val_loss: 0.1750 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1757 - loss: 0.1691 - val_accuracy: 0.1745 - val_loss: 0.1528 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1778 - loss: 0.1469 - val_accuracy: 0.1750 - val_loss: 0.1412 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1788 - loss: 0.1349 - val_accuracy: 0.1751 - val_loss: 0.1344 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1780 - loss: 0.1269 - val_accuracy: 0.1754 - val_loss: 0.1297 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1787 - loss: 0.1211 - val_accuracy: 0.1756 - val_loss: 0.1270 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1802 - loss: 0.1169 - val_accuracy: 0.1756 - val_loss: 0.1254 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1793 - loss: 0.1144 - val_accuracy: 0.1754 - val_loss: 0.1242 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1795 - loss: 0.1124 - val_accuracy: 0.1758 - val_loss: 0.1233 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando textcnn_k345  (embedding_dim=512)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.1765 - loss: 0.5828 - val_accuracy: 0.2222 - val_loss: 0.1233 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2309 - loss: 0.0750 - val_accuracy: 0.2293 - val_loss: 0.0901 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2373 - loss: 0.0398 - val_accuracy: 0.2317 - val_loss: 0.0813 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2402 - loss: 0.0263 - val_accuracy: 0.2328 - val_loss: 0.0784 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2412 - loss: 0.0200 - val_accuracy: 0.2333 - val_loss: 0.0772 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2422 - loss: 0.0163 - val_accuracy: 0.2333 - val_loss: 0.0778 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2426 - loss: 0.0140 - val_accuracy: 0.2337 - val_loss: 0.0785 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2430 - loss: 0.0120 - val_accuracy: 0.2338 - val_loss: 0.0791 - learning_rate: 5.0000e-04\n",
            "\n",
            "Resumen CNN (embedding=512):\n",
            "              model  accuracy  macro_precision  macro_recall  macro_f1  weighted_precision  weighted_recall  weighted_f1  support_total\n",
            "     conv_k3_nopool    0.7926           0.8441        0.6249    0.5984              0.8409           0.7926       0.7135           9010\n",
            "conv_k5_avgpool_up2    0.6029           0.5657        0.3698    0.2892              0.6699           0.6029       0.5316           9010\n",
            "conv_k5_maxpool_up2    0.6033           0.5735        0.3789    0.3056              0.7345           0.6033       0.5662           9010\n",
            "     conv_k5_nopool    0.8009           0.8028        0.6877    0.6115              0.8532           0.8009       0.7278           9010\n",
            "     conv_k7_nopool    0.8007           0.8312        0.6970    0.6471              0.8456           0.8007       0.7231           9010\n",
            "       textcnn_k345    0.8012           0.8350        0.6989    0.6332              0.8504           0.8012       0.7259           9010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Xarxes Recurrents.\n",
        "Afegiu capes recurrents al vostre model (LSTM, GRU). Expliqueu amb detall els valors que heu provat i la vostra motivaci√≥.     "
      ],
      "metadata": {
        "id": "MUNurWRpSiEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Bidirectional, TimeDistributed, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Funcions auxiliars\n",
        "# ------------------------------------------------------------------\n",
        "def preds_to_index(preds, seq_lens):\n",
        "    \"\"\"Converteix probabilitats en √≠ndexs (argmax) i descarta el padding segons la longitud real.\"\"\"\n",
        "    idx_preds = []\n",
        "    for pred, seq_len in zip(preds, seq_lens):\n",
        "        for l in range(int(seq_len)):\n",
        "            idx_preds.append(int(np.argmax(pred[l])))\n",
        "    return idx_preds\n",
        "\n",
        "def final_three_metrics(y_true_idx, y_pred_idx):\n",
        "    \"\"\"Retorna accuracy, macro(avg) i weighted(avg).\"\"\"\n",
        "    acc = accuracy_score(y_true_idx, y_pred_idx)\n",
        "    mP, mR, mF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"macro\", zero_division=1.0\n",
        "    )\n",
        "    wP, wR, wF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"weighted\", zero_division=1.0\n",
        "    )\n",
        "    return {\n",
        "        \"accuracy\": float(acc),\n",
        "        \"macro_precision\": float(mP),\n",
        "        \"macro_recall\": float(mR),\n",
        "        \"macro_f1\": float(mF1),\n",
        "        \"weighted_precision\": float(wP),\n",
        "        \"weighted_recall\": float(wR),\n",
        "        \"weighted_f1\": float(wF1),\n",
        "        \"support_total\": int(len(y_true_idx)),\n",
        "    }\n",
        "\n",
        "# Si no hi ha len_test_sequences, es calcula a partir de les entrades\n",
        "try:\n",
        "    len_test_sequences\n",
        "except NameError:\n",
        "    len_test_sequences = (test_pad_sequences != 0).sum(axis=1)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Par√†metres compartits\n",
        "# ------------------------------------------------------------------\n",
        "embedding_dim = 256\n",
        "vocab_size    = int(np.max(train_pad_sequences)) + 1\n",
        "max_len       = int(train_pad_sequences.shape[1])\n",
        "num_classes   = int(train_labels_one_hot.shape[-1])\n",
        "\n",
        "batch_size = 32\n",
        "epochs     = 10\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2),\n",
        "]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Constructors RNN per token (sortida [B, T, C])\n",
        "# ------------------------------------------------------------------\n",
        "def build_rnn_token(cell=\"lstm\", units=128, bidirectional=False, dropout=0.2, rec_dropout=0.0):\n",
        "    \"\"\"\n",
        "    Embedding(mask_zero=True) -> (Bi)LSTM/GRU return_sequences=True -> TimeDistributed(Dense softmax).\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                        input_length=max_len, mask_zero=True))\n",
        "    rnn_layer = LSTM(units, return_sequences=True, dropout=dropout, recurrent_dropout=rec_dropout) \\\n",
        "                if cell.lower() == \"lstm\" else \\\n",
        "                GRU(units,  return_sequences=True, dropout=dropout, recurrent_dropout=rec_dropout)\n",
        "\n",
        "    if bidirectional:\n",
        "        model.add(Bidirectional(rnn_layer))\n",
        "    else:\n",
        "        model.add(rnn_layer)\n",
        "\n",
        "    model.add(TimeDistributed(Dense(num_classes, activation=\"softmax\")))\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Experiments (LSTM / GRU, uni i bidireccional, 64 i 128)\n",
        "# ------------------------------------------------------------------\n",
        "experiments = [\n",
        "    (\"lstm_64\",    build_rnn_token(cell=\"lstm\", units=64,  bidirectional=False)),\n",
        "    (\"lstm_128\",   build_rnn_token(cell=\"lstm\", units=128, bidirectional=False)),\n",
        "    (\"bilstm_64\",  build_rnn_token(cell=\"lstm\", units=64,  bidirectional=True)),\n",
        "    (\"bilstm_128\", build_rnn_token(cell=\"lstm\", units=128, bidirectional=True)),\n",
        "    (\"gru_64\",     build_rnn_token(cell=\"gru\",  units=64,  bidirectional=False)),\n",
        "    (\"gru_128\",    build_rnn_token(cell=\"gru\",  units=128, bidirectional=False)),\n",
        "    (\"bigru_64\",   build_rnn_token(cell=\"gru\",  units=64,  bidirectional=True)),\n",
        "    (\"bigru_128\",  build_rnn_token(cell=\"gru\",  units=128, bidirectional=True)),\n",
        "]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Entrenament, avaluaci√≥ i taula de resultats\n",
        "# ------------------------------------------------------------------\n",
        "rows = []\n",
        "for name, model in experiments:\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"Entrenando {name}  (embedding_dim=256)\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    model.fit(\n",
        "        x=train_pad_sequences,\n",
        "        y=train_labels_one_hot,\n",
        "        sample_weight=train_w,\n",
        "        validation_data=(val_pad_sequences, val_labels_one_hot, val_w),\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    preds = model.predict(test_pad_sequences, batch_size=batch_size, verbose=0)\n",
        "    y_true_idx = preds_to_index(test_labels_one_hot, len_test_sequences)\n",
        "    y_pred_idx = preds_to_index(preds,                len_test_sequences)\n",
        "\n",
        "    met = final_three_metrics(y_true_idx, y_pred_idx)\n",
        "    rows.append({\n",
        "        \"model\": name,\n",
        "        \"accuracy\": met[\"accuracy\"],\n",
        "        \"macro_precision\": met[\"macro_precision\"],\n",
        "        \"macro_recall\": met[\"macro_recall\"],\n",
        "        \"macro_f1\": met[\"macro_f1\"],\n",
        "        \"weighted_precision\": met[\"weighted_precision\"],\n",
        "        \"weighted_recall\": met[\"weighted_recall\"],\n",
        "        \"weighted_f1\": met[\"weighted_f1\"],\n",
        "        \"support_total\": met[\"support_total\"],\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)[[\n",
        "    \"model\",\n",
        "    \"accuracy\",\n",
        "    \"macro_precision\", \"macro_recall\", \"macro_f1\",\n",
        "    \"weighted_precision\", \"weighted_recall\", \"weighted_f1\",\n",
        "    \"support_total\"\n",
        "]].sort_values(\"model\")\n",
        "\n",
        "print(\"\\nResumen RNN per-token (embedding=256):\")\n",
        "print(df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB2fWwhQSlJq",
        "outputId": "5fce4bb9-a39a-4e14-e0b9-27ecc71aa3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "Entrenando lstm_64  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.1470 - loss: 3.0097 - val_accuracy: 0.1818 - val_loss: 1.2097 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.1904 - loss: 1.0855 - val_accuracy: 0.1956 - val_loss: 0.9106 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2037 - loss: 0.7902 - val_accuracy: 0.2087 - val_loss: 0.6872 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2192 - loss: 0.5607 - val_accuracy: 0.2203 - val_loss: 0.5229 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2273 - loss: 0.4006 - val_accuracy: 0.2218 - val_loss: 0.4377 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2294 - loss: 0.3133 - val_accuracy: 0.2236 - val_loss: 0.3898 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2316 - loss: 0.2579 - val_accuracy: 0.2272 - val_loss: 0.3539 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2355 - loss: 0.2144 - val_accuracy: 0.2288 - val_loss: 0.3270 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2373 - loss: 0.1800 - val_accuracy: 0.2302 - val_loss: 0.3060 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2389 - loss: 0.1521 - val_accuracy: 0.2309 - val_loss: 0.2910 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando lstm_128  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.1532 - loss: 2.7947 - val_accuracy: 0.1931 - val_loss: 0.9553 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2052 - loss: 0.7646 - val_accuracy: 0.2171 - val_loss: 0.5872 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.2259 - loss: 0.4318 - val_accuracy: 0.2243 - val_loss: 0.4127 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2334 - loss: 0.2684 - val_accuracy: 0.2289 - val_loss: 0.3372 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2375 - loss: 0.1861 - val_accuracy: 0.2312 - val_loss: 0.2986 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2398 - loss: 0.1375 - val_accuracy: 0.2324 - val_loss: 0.2750 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2412 - loss: 0.1060 - val_accuracy: 0.2334 - val_loss: 0.2636 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.2426 - loss: 0.0833 - val_accuracy: 0.2341 - val_loss: 0.2539 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2431 - loss: 0.0682 - val_accuracy: 0.2344 - val_loss: 0.2494 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2437 - loss: 0.0574 - val_accuracy: 0.2347 - val_loss: 0.2462 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando bilstm_64  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.1507 - loss: 2.7526 - val_accuracy: 0.1832 - val_loss: 1.0820 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1948 - loss: 0.9077 - val_accuracy: 0.2115 - val_loss: 0.6569 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2224 - loss: 0.5031 - val_accuracy: 0.2233 - val_loss: 0.4320 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2308 - loss: 0.2981 - val_accuracy: 0.2275 - val_loss: 0.3427 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2360 - loss: 0.2030 - val_accuracy: 0.2305 - val_loss: 0.2926 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2394 - loss: 0.1449 - val_accuracy: 0.2325 - val_loss: 0.2632 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2411 - loss: 0.1084 - val_accuracy: 0.2336 - val_loss: 0.2457 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2423 - loss: 0.0845 - val_accuracy: 0.2341 - val_loss: 0.2338 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2432 - loss: 0.0671 - val_accuracy: 0.2347 - val_loss: 0.2267 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2440 - loss: 0.0545 - val_accuracy: 0.2353 - val_loss: 0.2238 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando bilstm_128  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.1548 - loss: 2.5349 - val_accuracy: 0.1965 - val_loss: 0.8644 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2094 - loss: 0.6793 - val_accuracy: 0.2213 - val_loss: 0.4884 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2293 - loss: 0.3302 - val_accuracy: 0.2287 - val_loss: 0.3390 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2373 - loss: 0.1833 - val_accuracy: 0.2320 - val_loss: 0.2864 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2407 - loss: 0.1177 - val_accuracy: 0.2338 - val_loss: 0.2629 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2425 - loss: 0.0836 - val_accuracy: 0.2346 - val_loss: 0.2514 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2436 - loss: 0.0611 - val_accuracy: 0.2351 - val_loss: 0.2444 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2445 - loss: 0.0457 - val_accuracy: 0.2354 - val_loss: 0.2423 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.2451 - loss: 0.0345 - val_accuracy: 0.2354 - val_loss: 0.2415 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2454 - loss: 0.0276 - val_accuracy: 0.2358 - val_loss: 0.2398 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando gru_64  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1518 - loss: 2.8536 - val_accuracy: 0.1960 - val_loss: 0.9406 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2104 - loss: 0.7430 - val_accuracy: 0.2210 - val_loss: 0.5160 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2287 - loss: 0.3658 - val_accuracy: 0.2250 - val_loss: 0.3969 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.2331 - loss: 0.2460 - val_accuracy: 0.2282 - val_loss: 0.3448 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2363 - loss: 0.1853 - val_accuracy: 0.2298 - val_loss: 0.3157 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2385 - loss: 0.1481 - val_accuracy: 0.2314 - val_loss: 0.2983 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2401 - loss: 0.1220 - val_accuracy: 0.2320 - val_loss: 0.2874 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2410 - loss: 0.1039 - val_accuracy: 0.2327 - val_loss: 0.2807 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2414 - loss: 0.0909 - val_accuracy: 0.2330 - val_loss: 0.2765 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2419 - loss: 0.0816 - val_accuracy: 0.2331 - val_loss: 0.2744 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando gru_128  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.1586 - loss: 2.5941 - val_accuracy: 0.2087 - val_loss: 0.7540 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2222 - loss: 0.5343 - val_accuracy: 0.2237 - val_loss: 0.4401 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2326 - loss: 0.2622 - val_accuracy: 0.2287 - val_loss: 0.3602 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2373 - loss: 0.1726 - val_accuracy: 0.2314 - val_loss: 0.3230 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2399 - loss: 0.1250 - val_accuracy: 0.2324 - val_loss: 0.3046 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2412 - loss: 0.0969 - val_accuracy: 0.2329 - val_loss: 0.2941 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2422 - loss: 0.0774 - val_accuracy: 0.2336 - val_loss: 0.2883 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2432 - loss: 0.0616 - val_accuracy: 0.2343 - val_loss: 0.2840 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2439 - loss: 0.0487 - val_accuracy: 0.2348 - val_loss: 0.2800 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2445 - loss: 0.0411 - val_accuracy: 0.2351 - val_loss: 0.2792 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando bigru_64  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.1570 - loss: 2.5901 - val_accuracy: 0.2106 - val_loss: 0.7390 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2232 - loss: 0.5217 - val_accuracy: 0.2235 - val_loss: 0.4257 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2319 - loss: 0.2614 - val_accuracy: 0.2288 - val_loss: 0.3487 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2368 - loss: 0.1745 - val_accuracy: 0.2307 - val_loss: 0.3113 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2393 - loss: 0.1282 - val_accuracy: 0.2321 - val_loss: 0.2904 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2408 - loss: 0.0988 - val_accuracy: 0.2330 - val_loss: 0.2792 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2419 - loss: 0.0789 - val_accuracy: 0.2336 - val_loss: 0.2723 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2427 - loss: 0.0647 - val_accuracy: 0.2344 - val_loss: 0.2673 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2435 - loss: 0.0530 - val_accuracy: 0.2348 - val_loss: 0.2636 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2442 - loss: 0.0429 - val_accuracy: 0.2350 - val_loss: 0.2617 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando bigru_128  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.1593 - loss: 2.3927 - val_accuracy: 0.2134 - val_loss: 0.6665 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2245 - loss: 0.4498 - val_accuracy: 0.2259 - val_loss: 0.3809 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2354 - loss: 0.2031 - val_accuracy: 0.2312 - val_loss: 0.3085 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2395 - loss: 0.1225 - val_accuracy: 0.2329 - val_loss: 0.2841 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2419 - loss: 0.0845 - val_accuracy: 0.2341 - val_loss: 0.2725 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.2434 - loss: 0.0617 - val_accuracy: 0.2349 - val_loss: 0.2693 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2441 - loss: 0.0470 - val_accuracy: 0.2352 - val_loss: 0.2671 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2450 - loss: 0.0351 - val_accuracy: 0.2356 - val_loss: 0.2665 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2454 - loss: 0.0265 - val_accuracy: 0.2355 - val_loss: 0.2700 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2458 - loss: 0.0205 - val_accuracy: 0.2357 - val_loss: 0.2722 - learning_rate: 0.0010\n",
            "\n",
            "Resumen RNN per-token (embedding=256):\n",
            "     model  accuracy  macro_precision  macro_recall  macro_f1  weighted_precision  weighted_recall  weighted_f1  support_total\n",
            " bigru_128    0.8058           0.9139        0.7801    0.7712              0.9808           0.8058       0.8027           9010\n",
            "  bigru_64    0.8060           0.9073        0.7719    0.7470              0.9813           0.8060       0.8024           9010\n",
            "bilstm_128    0.8051           0.8697        0.7820    0.7545              0.9675           0.8051       0.7908           9010\n",
            " bilstm_64    0.8042           0.9071        0.7210    0.7111              0.9808           0.8042       0.8013           9010\n",
            "   gru_128    0.8026           0.8683        0.7576    0.7236              0.9769           0.8026       0.7987           9010\n",
            "    gru_64    0.7999           0.8956        0.6765    0.6658              0.9283           0.7999       0.7591           9010\n",
            "  lstm_128    0.8032           0.9112        0.7609    0.7494              0.9710           0.8032       0.7933           9010\n",
            "   lstm_64    0.7947           0.8912        0.5250    0.4998              0.9728           0.7947       0.7873           9010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando con el mejor modelo de CNN"
      ],
      "metadata": {
        "id": "CtPvAC9Tp0Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Bidirectional, TimeDistributed, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Funcions auxiliars\n",
        "# ------------------------------------------------------------------\n",
        "def preds_to_index(preds, seq_lens):\n",
        "    \"\"\"Converteix probabilitats en √≠ndexs (argmax) i descarta el padding segons la longitud real.\"\"\"\n",
        "    idx_preds = []\n",
        "    for pred, seq_len in zip(preds, seq_lens):\n",
        "        for l in range(int(seq_len)):\n",
        "            idx_preds.append(int(np.argmax(pred[l])))\n",
        "    return idx_preds\n",
        "\n",
        "def final_three_metrics(y_true_idx, y_pred_idx):\n",
        "    \"\"\"Retorna accuracy, macro(avg) i weighted(avg).\"\"\"\n",
        "    acc = accuracy_score(y_true_idx, y_pred_idx)\n",
        "    mP, mR, mF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"macro\", zero_division=1.0\n",
        "    )\n",
        "    wP, wR, wF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"weighted\", zero_division=1.0\n",
        "    )\n",
        "    return {\n",
        "        \"accuracy\": float(acc),\n",
        "        \"macro_precision\": float(mP),\n",
        "        \"macro_recall\": float(mR),\n",
        "        \"macro_f1\": float(mF1),\n",
        "        \"weighted_precision\": float(wP),\n",
        "        \"weighted_recall\": float(wR),\n",
        "        \"weighted_f1\": float(wF1),\n",
        "        \"support_total\": int(len(y_true_idx)),\n",
        "    }\n",
        "\n",
        "# Si no hi ha len_test_sequences, es calcula a partir de les entrades\n",
        "try:\n",
        "    len_test_sequences\n",
        "except NameError:\n",
        "    len_test_sequences = (test_pad_sequences != 0).sum(axis=1)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Par√†metres compartits\n",
        "# ------------------------------------------------------------------\n",
        "embedding_dim = 256\n",
        "vocab_size    = int(np.max(train_pad_sequences)) + 1\n",
        "max_len       = int(train_pad_sequences.shape[1])\n",
        "num_classes   = int(train_labels_one_hot.shape[-1])\n",
        "\n",
        "batch_size = 32\n",
        "epochs     = 10\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2),\n",
        "]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Constructors RNN per token (sortida [B, T, C])\n",
        "# ------------------------------------------------------------------\n",
        "def build_rnn_token(cell=\"lstm\", units=128, bidirectional=False, dropout=0.2, rec_dropout=0.0):\n",
        "    \"\"\"\n",
        "    Embedding(mask_zero=True) -> (Bi)LSTM/GRU return_sequences=True -> TimeDistributed(Dense softmax).\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                        input_length=max_len, mask_zero=True))\n",
        "    rnn_layer = LSTM(units, return_sequences=True, dropout=dropout, recurrent_dropout=rec_dropout) \\\n",
        "                if cell.lower() == \"lstm\" else \\\n",
        "                GRU(units,  return_sequences=True, dropout=dropout, recurrent_dropout=rec_dropout)\n",
        "\n",
        "    if bidirectional:\n",
        "        model.add(Bidirectional(rnn_layer))\n",
        "    else:\n",
        "        model.add(rnn_layer)\n",
        "\n",
        "    # Projecci√≥ per token a num_classes\n",
        "    model.add(TimeDistributed(Dense(num_classes, activation=\"softmax\")))\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "\n",
        "def build_conv_k7_nopool():\n",
        "    \"\"\"CNN per token amb kernel 7 i sense pooling.\"\"\"\n",
        "    inp = keras.Input(shape=(max_len,), dtype=\"int32\")\n",
        "    x = Embedding(input_dim=vocab_size,\n",
        "                  output_dim=embedding_dim,\n",
        "                  input_length=max_len,\n",
        "                  mask_zero=False)(inp)\n",
        "    x = Conv1D(filters=128, kernel_size=7, padding=\"same\", activation=\"relu\")(x)\n",
        "    out = Conv1D(filters=num_classes, kernel_size=1, padding=\"same\", activation=\"softmax\")(x)\n",
        "    model = keras.Model(inp, out)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Afegeix la millor CNN al principi de la llista d'experiments\n",
        "experiments = [\n",
        "    (\"conv_k7_nopool\", build_conv_k7_nopool()),\n",
        "    (\"lstm_64\",    build_rnn_token(cell=\"lstm\", units=64,  bidirectional=False)),\n",
        "    (\"lstm_128\",   build_rnn_token(cell=\"lstm\", units=128, bidirectional=False)),\n",
        "    (\"bilstm_64\",  build_rnn_token(cell=\"lstm\", units=64,  bidirectional=True)),\n",
        "    (\"bilstm_128\", build_rnn_token(cell=\"lstm\", units=128, bidirectional=True)),\n",
        "    (\"gru_64\",     build_rnn_token(cell=\"gru\",  units=64,  bidirectional=False)),\n",
        "    (\"gru_128\",    build_rnn_token(cell=\"gru\",  units=128, bidirectional=False)),\n",
        "    (\"bigru_64\",   build_rnn_token(cell=\"gru\",  units=64,  bidirectional=True)),\n",
        "    (\"bigru_128\",  build_rnn_token(cell=\"gru\",  units=128, bidirectional=True)),\n",
        "]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Entrenament, avaluaci√≥ i taula amb les m√®triques finals\n",
        "# ------------------------------------------------------------------\n",
        "rows = []\n",
        "for name, model in experiments:\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"Entrenando {name}  (embedding_dim=256)\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    model.fit(\n",
        "        x=train_pad_sequences,\n",
        "        y=train_labels_one_hot,\n",
        "        sample_weight=train_w,\n",
        "        validation_data=(val_pad_sequences, val_labels_one_hot, val_w),\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    pre\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7QsAKXyp3N5",
        "outputId": "a3d54a36-bac5-4656-c911-cad2ec47d812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "Entrenando conv_k7_nopool  (embedding_dim=256)\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.1751 - loss: 0.5585 - val_accuracy: 0.2191 - val_loss: 0.1396 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2297 - loss: 0.0859 - val_accuracy: 0.2294 - val_loss: 0.0911 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2383 - loss: 0.0387 - val_accuracy: 0.2322 - val_loss: 0.0809 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2416 - loss: 0.0229 - val_accuracy: 0.2334 - val_loss: 0.0785 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2431 - loss: 0.0159 - val_accuracy: 0.2339 - val_loss: 0.0784 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2437 - loss: 0.0120 - val_accuracy: 0.2342 - val_loss: 0.0794 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2444 - loss: 0.0091 - val_accuracy: 0.2343 - val_loss: 0.0797 - learning_rate: 5.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2447 - loss: 0.0077 - val_accuracy: 0.2343 - val_loss: 0.0808 - learning_rate: 5.0000e-04\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando lstm_64  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.1453 - loss: 3.0651 - val_accuracy: 0.1724 - val_loss: 1.2447 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1792 - loss: 1.1320 - val_accuracy: 0.1913 - val_loss: 0.9591 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2008 - loss: 0.8418 - val_accuracy: 0.2097 - val_loss: 0.7359 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2192 - loss: 0.6046 - val_accuracy: 0.2199 - val_loss: 0.5404 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2274 - loss: 0.4181 - val_accuracy: 0.2221 - val_loss: 0.4405 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2296 - loss: 0.3204 - val_accuracy: 0.2246 - val_loss: 0.3872 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2330 - loss: 0.2616 - val_accuracy: 0.2275 - val_loss: 0.3520 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2357 - loss: 0.2190 - val_accuracy: 0.2294 - val_loss: 0.3267 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2373 - loss: 0.1877 - val_accuracy: 0.2301 - val_loss: 0.3090 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2381 - loss: 0.1630 - val_accuracy: 0.2309 - val_loss: 0.2960 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando lstm_128  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.1534 - loss: 2.7742 - val_accuracy: 0.1929 - val_loss: 0.9670 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2044 - loss: 0.7814 - val_accuracy: 0.2155 - val_loss: 0.6055 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2248 - loss: 0.4506 - val_accuracy: 0.2240 - val_loss: 0.4272 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2326 - loss: 0.2812 - val_accuracy: 0.2288 - val_loss: 0.3443 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2372 - loss: 0.1927 - val_accuracy: 0.2306 - val_loss: 0.3007 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2396 - loss: 0.1413 - val_accuracy: 0.2321 - val_loss: 0.2747 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2412 - loss: 0.1091 - val_accuracy: 0.2332 - val_loss: 0.2602 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2425 - loss: 0.0838 - val_accuracy: 0.2338 - val_loss: 0.2492 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2432 - loss: 0.0689 - val_accuracy: 0.2345 - val_loss: 0.2429 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2438 - loss: 0.0568 - val_accuracy: 0.2346 - val_loss: 0.2414 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando bilstm_64  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.1506 - loss: 2.7610 - val_accuracy: 0.1845 - val_loss: 1.0562 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1960 - loss: 0.8844 - val_accuracy: 0.2126 - val_loss: 0.6461 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2230 - loss: 0.4977 - val_accuracy: 0.2240 - val_loss: 0.4216 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2317 - loss: 0.2887 - val_accuracy: 0.2284 - val_loss: 0.3324 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2365 - loss: 0.1943 - val_accuracy: 0.2311 - val_loss: 0.2862 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2398 - loss: 0.1383 - val_accuracy: 0.2330 - val_loss: 0.2604 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2412 - loss: 0.1039 - val_accuracy: 0.2335 - val_loss: 0.2443 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2425 - loss: 0.0802 - val_accuracy: 0.2342 - val_loss: 0.2356 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2436 - loss: 0.0640 - val_accuracy: 0.2349 - val_loss: 0.2291 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2442 - loss: 0.0525 - val_accuracy: 0.2352 - val_loss: 0.2275 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando bilstm_128  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.1536 - loss: 2.5439 - val_accuracy: 0.1982 - val_loss: 0.8718 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2096 - loss: 0.6869 - val_accuracy: 0.2201 - val_loss: 0.5032 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2288 - loss: 0.3433 - val_accuracy: 0.2281 - val_loss: 0.3453 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2373 - loss: 0.1889 - val_accuracy: 0.2321 - val_loss: 0.2898 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2403 - loss: 0.1214 - val_accuracy: 0.2336 - val_loss: 0.2635 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.2424 - loss: 0.0852 - val_accuracy: 0.2346 - val_loss: 0.2503 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2438 - loss: 0.0593 - val_accuracy: 0.2352 - val_loss: 0.2438 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2446 - loss: 0.0436 - val_accuracy: 0.2353 - val_loss: 0.2398 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2453 - loss: 0.0326 - val_accuracy: 0.2356 - val_loss: 0.2355 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2455 - loss: 0.0265 - val_accuracy: 0.2355 - val_loss: 0.2395 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando gru_64  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.1500 - loss: 2.8784 - val_accuracy: 0.1993 - val_loss: 0.9286 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2148 - loss: 0.7180 - val_accuracy: 0.2213 - val_loss: 0.5041 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.2289 - loss: 0.3608 - val_accuracy: 0.2246 - val_loss: 0.3983 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2327 - loss: 0.2499 - val_accuracy: 0.2278 - val_loss: 0.3469 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2359 - loss: 0.1880 - val_accuracy: 0.2300 - val_loss: 0.3164 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2386 - loss: 0.1484 - val_accuracy: 0.2316 - val_loss: 0.2977 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2400 - loss: 0.1213 - val_accuracy: 0.2322 - val_loss: 0.2859 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2407 - loss: 0.1032 - val_accuracy: 0.2329 - val_loss: 0.2777 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2413 - loss: 0.0885 - val_accuracy: 0.2331 - val_loss: 0.2728 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2421 - loss: 0.0770 - val_accuracy: 0.2336 - val_loss: 0.2693 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando gru_128  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.1585 - loss: 2.5905 - val_accuracy: 0.2094 - val_loss: 0.7400 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2225 - loss: 0.5268 - val_accuracy: 0.2237 - val_loss: 0.4368 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2323 - loss: 0.2620 - val_accuracy: 0.2290 - val_loss: 0.3562 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2375 - loss: 0.1716 - val_accuracy: 0.2311 - val_loss: 0.3168 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2399 - loss: 0.1241 - val_accuracy: 0.2323 - val_loss: 0.2978 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2412 - loss: 0.0964 - val_accuracy: 0.2330 - val_loss: 0.2878 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2421 - loss: 0.0775 - val_accuracy: 0.2337 - val_loss: 0.2805 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2431 - loss: 0.0626 - val_accuracy: 0.2345 - val_loss: 0.2775 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2436 - loss: 0.0524 - val_accuracy: 0.2347 - val_loss: 0.2775 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2441 - loss: 0.0442 - val_accuracy: 0.2348 - val_loss: 0.2784 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando bigru_64  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.1552 - loss: 2.5903 - val_accuracy: 0.2076 - val_loss: 0.7553 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2216 - loss: 0.5395 - val_accuracy: 0.2227 - val_loss: 0.4285 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2315 - loss: 0.2676 - val_accuracy: 0.2286 - val_loss: 0.3446 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2367 - loss: 0.1771 - val_accuracy: 0.2312 - val_loss: 0.3030 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2395 - loss: 0.1282 - val_accuracy: 0.2321 - val_loss: 0.2791 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2410 - loss: 0.0969 - val_accuracy: 0.2333 - val_loss: 0.2649 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2423 - loss: 0.0765 - val_accuracy: 0.2340 - val_loss: 0.2567 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2432 - loss: 0.0610 - val_accuracy: 0.2343 - val_loss: 0.2518 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2439 - loss: 0.0494 - val_accuracy: 0.2349 - val_loss: 0.2493 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.2445 - loss: 0.0409 - val_accuracy: 0.2350 - val_loss: 0.2490 - learning_rate: 0.0010\n",
            "\n",
            "==========================================================================================\n",
            "Entrenando bigru_128  (embedding_dim=256)\n",
            "==========================================================================================\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.1599 - loss: 2.3870 - val_accuracy: 0.2141 - val_loss: 0.6594 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2247 - loss: 0.4433 - val_accuracy: 0.2259 - val_loss: 0.3877 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2345 - loss: 0.2119 - val_accuracy: 0.2311 - val_loss: 0.3146 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2394 - loss: 0.1292 - val_accuracy: 0.2331 - val_loss: 0.2853 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2415 - loss: 0.0892 - val_accuracy: 0.2342 - val_loss: 0.2734 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2430 - loss: 0.0651 - val_accuracy: 0.2350 - val_loss: 0.2695 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2441 - loss: 0.0480 - val_accuracy: 0.2353 - val_loss: 0.2696 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2448 - loss: 0.0365 - val_accuracy: 0.2357 - val_loss: 0.2702 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2454 - loss: 0.0267 - val_accuracy: 0.2358 - val_loss: 0.2683 - learning_rate: 5.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2456 - loss: 0.0229 - val_accuracy: 0.2360 - val_loss: 0.2693 - learning_rate: 5.0000e-04\n",
            "\n",
            "Resumen RNN per-token (embedding=256):\n",
            "         model  accuracy  macro_precision  macro_recall  macro_f1  weighted_precision  weighted_recall  weighted_f1  support_total\n",
            "     bigru_128    0.8058           0.8969        0.7803    0.7626              0.9809           0.8058       0.8027           9010\n",
            "      bigru_64    0.8063           0.9059        0.7793    0.7561              0.9814           0.8063       0.8032           9010\n",
            "    bilstm_128    0.8054           0.8830        0.7917    0.7692              0.9783           0.8054       0.8010           9010\n",
            "     bilstm_64    0.8051           0.9069        0.7698    0.7563              0.9738           0.8051       0.7954           9010\n",
            "conv_k7_nopool    0.8019           0.8084        0.7171    0.6515              0.8499           0.8019       0.7267           9010\n",
            "       gru_128    0.8013           0.8913        0.7326    0.7185              0.9299           0.8013       0.7616           9010\n",
            "        gru_64    0.7990           0.8864        0.6767    0.6415              0.9743           0.7990       0.7935           9010\n",
            "      lstm_128    0.8017           0.8728        0.7539    0.7165              0.9759           0.8017       0.7974           9010\n",
            "       lstm_64    0.7917           0.8414        0.5175    0.4480              0.9679           0.7917       0.7832           9010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4. ** Transformer** Afegiu blocs de Transformer al vostre model. Expliqueu amb detall els valors que heu provat i la vostra motivaci√≥."
      ],
      "metadata": {
        "id": "Ag3AB80vvLdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# =========================\n",
        "# 0) Configuraci√≥\n",
        "# =========================\n",
        "tf.random.set_seed(7)\n",
        "np.random.seed(7)\n",
        "\n",
        "max_len     = int(train_pad_sequences.shape[1])\n",
        "vocab_size  = int(np.max(train_pad_sequences)) + 1\n",
        "num_classes = int(train_labels_one_hot.shape[-1])   # 120 (inclou <pad>)\n",
        "embedding_dim = 256\n",
        "\n",
        "# Pesos per ignorar <pad>\n",
        "try:\n",
        "    train_w, val_w, test_w\n",
        "except NameError:\n",
        "    PAD_IX = num_classes - 1\n",
        "    train_w = (np.argmax(train_labels_one_hot, -1) != PAD_IX).astype(\"float32\")\n",
        "    val_w   = (np.argmax(val_labels_one_hot,   -1) != PAD_IX).astype(\"float32\")\n",
        "    test_w  = (np.argmax(test_labels_one_hot,  -1) != PAD_IX).astype(\"float32\")\n",
        "\n",
        "# Longituds reals\n",
        "try:\n",
        "    len_test_sequences\n",
        "except NameError:\n",
        "    len_test_sequences = np.sum(test_pad_sequences != 0, axis=1).tolist()\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.5),\n",
        "]\n",
        "\n",
        "# =========================\n",
        "# Utilitats: m√®triques\n",
        "# =========================\n",
        "def preds_to_index(preds, seq_lens):\n",
        "    \"\"\"Argmax per token tallant pel nombre real de tokens (ignora padding).\"\"\"\n",
        "    idx = []\n",
        "    for p, L in zip(preds, seq_lens):\n",
        "        idx.extend(np.argmax(p[:L], axis=-1))\n",
        "    return idx\n",
        "\n",
        "def macro_table_row(name, y_true_oh, y_pred_proba, seq_lens):\n",
        "    \"\"\"Calcula valors agregats per a la taula (accuracy, macro i weighted).\"\"\"\n",
        "    y_true_idx = preds_to_index(y_true_oh, seq_lens)\n",
        "    y_pred_idx = preds_to_index(y_pred_proba, seq_lens)\n",
        "    rep = classification_report(y_true_idx, y_pred_idx, output_dict=True, zero_division=0.0)\n",
        "    return {\n",
        "        \"modelo\": name,\n",
        "        \"acc\":    rep.get(\"accuracy\", 0.0),\n",
        "        \"prec_macro\":  rep[\"macro avg\"][\"precision\"],\n",
        "        \"rec_macro\":   rep[\"macro avg\"][\"recall\"],\n",
        "        \"f1_macro\":    rep[\"macro avg\"][\"f1-score\"],\n",
        "        \"prec_weight\": rep[\"weighted avg\"][\"precision\"],\n",
        "        \"rec_weight\":  rep[\"weighted avg\"][\"recall\"],\n",
        "        \"f1_weight\":   rep[\"weighted avg\"][\"f1-score\"],\n",
        "    }\n",
        "\n",
        "def print_results_table(rows):\n",
        "    \"\"\"Imprimeix la taula resum dels experiments.\"\"\"\n",
        "    header = f'{\"modelo\":20s}  acc    P_mac  R_mac  F1_mac  P_wgt  R_wgt  F1_wgt'\n",
        "    print(\"\\n\" + header)\n",
        "    print(\"-\"*len(header))\n",
        "    for r in rows:\n",
        "        print(f'{r[\"modelo\"]:20s}  {r[\"acc\"]:.4f}  {r[\"prec_macro\"]:.4f}  {r[\"rec_macro\"]:.4f}  {r[\"f1_macro\"]:.4f}  {r[\"prec_weight\"]:.4f}  {r[\"rec_weight\"]:.4f}  {r[\"f1_weight\"]:.4f}')\n",
        "\n",
        "# =========================\n",
        "# Constructor Transformer (blocs propis)\n",
        "# =========================\n",
        "def build_transformer(name, num_heads=4, ff_dim=1024, depth=2, rate=0.1):\n",
        "    \"\"\"Token+Positional Embedding -> N blocs Transformer -> Dense per token.\"\"\"\n",
        "    inp = keras.Input(shape=(max_len,), dtype=\"int32\")\n",
        "    x = TokenAndPositionEmbedding(maxlen=max_len, vocab_size=vocab_size, embed_dim=embedding_dim)(inp)\n",
        "    for _ in range(depth):\n",
        "        x = TransformerBlock(embed_dim=embedding_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate)(x)\n",
        "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
        "    m = keras.Model(inp, out, name=name)\n",
        "    m.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return m\n",
        "\n",
        "# =========================\n",
        "# Experiments (sense CNN/RNN)\n",
        "# =========================\n",
        "experiments = [\n",
        "    (\"trf_base_s_h4_d1_ff512\",  build_transformer(\"trf_base_s_h4_d1_ff512\",  num_heads=4, ff_dim=512,  depth=1, rate=0.1)),\n",
        "    (\"trf_base_m_h4_d2_ff1024\", build_transformer(\"trf_base_m_h4_d2_ff1024\", num_heads=4, ff_dim=1024, depth=2, rate=0.1)),\n",
        "    (\"trf_base_h_h8_d2_ff1024\", build_transformer(\"trf_base_h_h8_d2_ff1024\", num_heads=8, ff_dim=1024, depth=2, rate=0.1)),\n",
        "    (\"trf_base_d_h4_d3_ff1024\", build_transformer(\"trf_base_d_h4_d3_ff1024\", num_heads=4, ff_dim=1024, depth=3, rate=0.1)),\n",
        "]\n",
        "\n",
        "# =========================\n",
        "# Entrenar + avaluar + taula\n",
        "# =========================\n",
        "rows = []\n",
        "for name, model in experiments:\n",
        "    print(f\"\\n=== Entrenando {name} ===\")\n",
        "    model.fit(\n",
        "        train_pad_sequences, train_labels_one_hot,\n",
        "        sample_weight=train_w,\n",
        "        validation_data=(val_pad_sequences, val_labels_one_hot, val_w),\n",
        "        epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=1\n",
        "    )\n",
        "    preds = model.predict(test_pad_sequences, batch_size=batch_size, verbose=0)\n",
        "    rows.append(macro_table_row(name, test_labels_one_hot, preds, len_test_sequences))\n",
        "\n",
        "print_results_table(rows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ns32Y8xrrI",
        "outputId": "579c064e-e255-490d-b6fd-11c663ec819e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Entrenando trf_base_s_h4_d1_ff512 ===\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 59ms/step - accuracy: 0.1946 - loss: 0.2379 - val_accuracy: 0.2139 - val_loss: 0.1140 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.2213 - loss: 0.0696 - val_accuracy: 0.2159 - val_loss: 0.1089 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2251 - loss: 0.0548 - val_accuracy: 0.2224 - val_loss: 0.0976 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2328 - loss: 0.0401 - val_accuracy: 0.2263 - val_loss: 0.0910 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2374 - loss: 0.0270 - val_accuracy: 0.2285 - val_loss: 0.0854 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2410 - loss: 0.0179 - val_accuracy: 0.2298 - val_loss: 0.0846 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2424 - loss: 0.0139 - val_accuracy: 0.2314 - val_loss: 0.0837 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2434 - loss: 0.0107 - val_accuracy: 0.2318 - val_loss: 0.0852 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2441 - loss: 0.0086 - val_accuracy: 0.2316 - val_loss: 0.0897 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2452 - loss: 0.0056 - val_accuracy: 0.2327 - val_loss: 0.0868 - learning_rate: 5.0000e-04\n",
            "\n",
            "=== Entrenando trf_base_m_h4_d2_ff1024 ===\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 85ms/step - accuracy: 0.1849 - loss: 0.3030 - val_accuracy: 0.2208 - val_loss: 0.1051 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2295 - loss: 0.0554 - val_accuracy: 0.2244 - val_loss: 0.0930 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2352 - loss: 0.0362 - val_accuracy: 0.2285 - val_loss: 0.0858 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2387 - loss: 0.0255 - val_accuracy: 0.2304 - val_loss: 0.0800 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2414 - loss: 0.0179 - val_accuracy: 0.2303 - val_loss: 0.0819 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2423 - loss: 0.0146 - val_accuracy: 0.2303 - val_loss: 0.0831 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2435 - loss: 0.0105 - val_accuracy: 0.2335 - val_loss: 0.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2453 - loss: 0.0052 - val_accuracy: 0.2343 - val_loss: 0.0742 - learning_rate: 5.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2462 - loss: 0.0024 - val_accuracy: 0.2342 - val_loss: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2464 - loss: 0.0020 - val_accuracy: 0.2341 - val_loss: 0.0817 - learning_rate: 5.0000e-04\n",
            "\n",
            "=== Entrenando trf_base_h_h8_d2_ff1024 ===\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 94ms/step - accuracy: 0.1606 - loss: 0.4487 - val_accuracy: 0.2182 - val_loss: 0.1092 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.2274 - loss: 0.0628 - val_accuracy: 0.2244 - val_loss: 0.0916 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2343 - loss: 0.0386 - val_accuracy: 0.2269 - val_loss: 0.0844 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2378 - loss: 0.0271 - val_accuracy: 0.2295 - val_loss: 0.0799 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2408 - loss: 0.0185 - val_accuracy: 0.2310 - val_loss: 0.0767 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2415 - loss: 0.0154 - val_accuracy: 0.2306 - val_loss: 0.0790 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2418 - loss: 0.0153 - val_accuracy: 0.2310 - val_loss: 0.0801 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2432 - loss: 0.0111 - val_accuracy: 0.2331 - val_loss: 0.0763 - learning_rate: 5.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.2452 - loss: 0.0048 - val_accuracy: 0.2337 - val_loss: 0.0792 - learning_rate: 5.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2461 - loss: 0.0026 - val_accuracy: 0.2335 - val_loss: 0.0809 - learning_rate: 5.0000e-04\n",
            "\n",
            "=== Entrenando trf_base_d_h4_d3_ff1024 ===\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 105ms/step - accuracy: 0.1660 - loss: 0.4278 - val_accuracy: 0.2203 - val_loss: 0.1071 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.2289 - loss: 0.0603 - val_accuracy: 0.2265 - val_loss: 0.0891 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.2356 - loss: 0.0366 - val_accuracy: 0.2288 - val_loss: 0.0842 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.2381 - loss: 0.0277 - val_accuracy: 0.2292 - val_loss: 0.0837 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.2393 - loss: 0.0239 - val_accuracy: 0.2314 - val_loss: 0.0775 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.2419 - loss: 0.0168 - val_accuracy: 0.2308 - val_loss: 0.0808 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.2412 - loss: 0.0173 - val_accuracy: 0.2310 - val_loss: 0.0846 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.2434 - loss: 0.0110 - val_accuracy: 0.2336 - val_loss: 0.0788 - learning_rate: 5.0000e-04\n",
            "\n",
            "modelo                acc    P_mac  R_mac  F1_mac  P_wgt  R_wgt  F1_wgt\n",
            "-----------------------------------------------------------------------\n",
            "trf_base_s_h4_d1_ff512  0.7908  0.5162  0.5828  0.4882  0.7818  0.7908  0.7814\n",
            "trf_base_m_h4_d2_ff1024  0.8012  0.5215  0.6312  0.5338  0.7655  0.8012  0.7761\n",
            "trf_base_h_h8_d2_ff1024  0.7990  0.4741  0.5676  0.4790  0.7714  0.7990  0.7797\n",
            "trf_base_d_h4_d3_ff1024  0.7928  0.5448  0.5540  0.5165  0.7302  0.7928  0.7567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Regularitzaci√≥.\n",
        "Quan proveu configuracions amb m√©s par√†metres veureu que el model comen√ßa a tenir overfitting molt prompte durant l'entrenament. Afegiu Dropout al vostre model. Heu d'explicar la vostra decisi√≥ de valors i de posici√≥ dins de la xarxa.\n"
      ],
      "metadata": {
        "id": "hdIF0UkQLeX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, TimeDistributed, Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# Helpers (m√®triques i conversi√≥)\n",
        "def preds_to_index(preds, seq_lens):\n",
        "    \"\"\"Argmax per token i tall per longitud real (ignora padding).\"\"\"\n",
        "    idx_preds = []\n",
        "    for pred, seq_len in zip(preds, seq_lens):\n",
        "        for l in range(int(seq_len)):\n",
        "            idx_preds.append(int(np.argmax(pred[l])))\n",
        "    return idx_preds\n",
        "\n",
        "def final_three_metrics(y_true_idx, y_pred_idx):\n",
        "    \"\"\"Retorna accuracy i macro/weighted (precision, recall, F1).\"\"\"\n",
        "    acc = accuracy_score(y_true_idx, y_pred_idx)\n",
        "    mP, mR, mF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"macro\", zero_division=1.0\n",
        "    )\n",
        "    wP, wR, wF1, _ = precision_recall_fscore_support(\n",
        "        y_true_idx, y_pred_idx, average=\"weighted\", zero_division=1.0\n",
        "    )\n",
        "    return {\n",
        "        \"accuracy\": float(acc),\n",
        "        \"macro_precision\": float(mP),\n",
        "        \"macro_recall\": float(mR),\n",
        "        \"macro_f1\": float(mF1),\n",
        "        \"weighted_precision\": float(wP),\n",
        "        \"weighted_recall\": float(wR),\n",
        "        \"weighted_f1\": float(wF1),\n",
        "        \"support_total\": int(len(y_true_idx)),\n",
        "    }\n",
        "\n",
        "# Longituds reals si no existeixen\n",
        "try:\n",
        "    len_test_sequences\n",
        "except NameError:\n",
        "    len_test_sequences = (test_pad_sequences != 0).sum(axis=1)\n",
        "\n",
        "# Par√†metres fixos (LSTM_64)\n",
        "embedding_dim = 256\n",
        "vocab_size    = int(np.max(train_pad_sequences)) + 1\n",
        "max_len       = int(train_pad_sequences.shape[1])\n",
        "num_classes   = int(train_labels_one_hot.shape[-1])\n",
        "\n",
        "batch_size = 32\n",
        "epochs     = 10\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2),\n",
        "]\n",
        "\n",
        "# Builder LSTM64 (sense dropout intern)\n",
        "def build_lstm64_dropout(emb_spatial_do=0.0,\n",
        "                         post_lstm_do=0.0,\n",
        "                         post_dense_do=0.0):\n",
        "    \"\"\"\n",
        "    Embedding(mask_zero=True, dim=embedding_dim)\n",
        "    -> [SpatialDropout1D opcional]\n",
        "    -> LSTM(64, return_sequences=True)  # sense dropout intern\n",
        "    -> [Dropout post-LSTM opcional]\n",
        "    -> [TimeDistributed(Dense(128,relu)) + Dropout opcional]\n",
        "    -> TimeDistributed(Dense(num_classes, softmax))\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                        input_length=max_len, mask_zero=True))\n",
        "\n",
        "    if emb_spatial_do and emb_spatial_do > 0:\n",
        "        model.add(SpatialDropout1D(emb_spatial_do))\n",
        "\n",
        "    model.add(LSTM(64, return_sequences=True))\n",
        "\n",
        "    if post_lstm_do and post_lstm_do > 0:\n",
        "        model.add(Dropout(post_lstm_do))\n",
        "\n",
        "    if post_dense_do and post_dense_do > 0:\n",
        "        model.add(TimeDistributed(Dense(128, activation=\"relu\")))\n",
        "        model.add(Dropout(post_dense_do))\n",
        "\n",
        "    model.add(TimeDistributed(Dense(num_classes, activation=\"softmax\")))\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Configuracions (on/off de drops externs)\n",
        "dropout_levels = [0.05, 0.10, 0.20, 0.40, 0.60]\n",
        "\n",
        "drop_configs = [\n",
        "    (\"all_on\", dict(use_drop_embed=True, use_post_lstm=True, use_post_dense=True)),\n",
        "    (\"embed_postlstm\", dict(use_drop_embed=True, use_post_lstm=True, use_post_dense=False)),\n",
        "    (\"embed_postdense\", dict(use_drop_embed=True, use_post_lstm=False, use_post_dense=True)),\n",
        "    (\"embed_only\", dict(use_drop_embed=True, use_post_lstm=False, use_post_dense=False)),\n",
        "    (\"postlstm_only\", dict(use_drop_embed=False, use_post_lstm=True, use_post_dense=False)),\n",
        "    (\"postdense_only\", dict(use_drop_embed=False, use_post_lstm=False, use_post_dense=True)),\n",
        "]\n",
        "\n",
        "# Entrenament + avaluaci√≥ + taula\n",
        "rows = []\n",
        "\n",
        "for cfg_name, switches in drop_configs:\n",
        "    for drop in dropout_levels:\n",
        "        name = f\"lstm_64_emb512__{cfg_name}__drop{drop}\"\n",
        "        print(\"\\n\" + \"=\"*110)\n",
        "        print(f\"Entrenando {name}\")\n",
        "        print(\"=\"*110)\n",
        "\n",
        "        emb_do  = drop if switches[\"use_drop_embed\"] else 0.0\n",
        "        post_do = drop if switches[\"use_post_lstm\"]   else 0.0\n",
        "        pdense  = drop if switches[\"use_post_dense\"]  else 0.0\n",
        "\n",
        "        model = build_lstm64_dropout(\n",
        "            emb_spatial_do=emb_do,\n",
        "            post_lstm_do=post_do,\n",
        "            post_dense_do=pdense\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            x=train_pad_sequences,\n",
        "            y=train_labels_one_hot,\n",
        "            sample_weight=train_w,\n",
        "            validation_data=(val_pad_sequences, val_labels_one_hot, val_w),\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        preds = model.predict(test_pad_sequences, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        y_true_idx = preds_to_index(test_labels_one_hot, len_test_sequences)\n",
        "        y_pred_idx = preds_to_index(preds,                len_test_sequences)\n",
        "\n",
        "        met = final_three_metrics(y_true_idx, y_pred_idx)\n",
        "        rows.append({\n",
        "            \"model\": name,\n",
        "            \"accuracy\": met[\"accuracy\"],\n",
        "            \"macro_precision\": met[\"macro_precision\"],\n",
        "            \"macro_recall\": met[\"macro_recall\"],\n",
        "            \"macro_f1\": met[\"macro_f1\"],\n",
        "            \"weighted_precision\": met[\"weighted_precision\"],\n",
        "            \"weighted_recall\": met[\"weighted_recall\"],\n",
        "            \"weighted_f1\": met[\"weighted_f1\"],\n",
        "            \"support_total\": met[\"support_total\"],\n",
        "        })\n",
        "\n",
        "# Taula final\n",
        "df = pd.DataFrame(rows)[[\n",
        "    \"model\",\n",
        "    \"accuracy\",\n",
        "    \"macro_precision\", \"macro_recall\", \"macro_f1\",\n",
        "    \"weighted_precision\", \"weighted_recall\", \"weighted_f1\",\n",
        "    \"support_total\"\n",
        "]].sort_values([\"model\"])\n",
        "\n",
        "print(\"\\nResumen LSTM64 (emb=512) SIN dropout interno:\")\n",
        "print(df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKBxPDKhLf5C",
        "outputId": "2cd3457a-29e1-48b0-cfcc-9ce2976c6aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__all_on__drop0.05\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.1509 - loss: 2.9087 - val_accuracy: 0.1920 - val_loss: 0.9920 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2025 - loss: 0.7785 - val_accuracy: 0.2135 - val_loss: 0.6315 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2231 - loss: 0.4166 - val_accuracy: 0.2246 - val_loss: 0.4637 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2330 - loss: 0.2444 - val_accuracy: 0.2293 - val_loss: 0.3979 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.2376 - loss: 0.1673 - val_accuracy: 0.2311 - val_loss: 0.3701 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2399 - loss: 0.1237 - val_accuracy: 0.2321 - val_loss: 0.3548 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2413 - loss: 0.0993 - val_accuracy: 0.2329 - val_loss: 0.3459 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2421 - loss: 0.0828 - val_accuracy: 0.2329 - val_loss: 0.3406 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2427 - loss: 0.0688 - val_accuracy: 0.2337 - val_loss: 0.3291 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.2433 - loss: 0.0574 - val_accuracy: 0.2337 - val_loss: 0.3365 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__all_on__drop0.1\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.1503 - loss: 2.9366 - val_accuracy: 0.1886 - val_loss: 0.9721 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2015 - loss: 0.7772 - val_accuracy: 0.2160 - val_loss: 0.6284 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2239 - loss: 0.4253 - val_accuracy: 0.2261 - val_loss: 0.4461 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2327 - loss: 0.2548 - val_accuracy: 0.2294 - val_loss: 0.3899 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2372 - loss: 0.1751 - val_accuracy: 0.2313 - val_loss: 0.3629 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.2394 - loss: 0.1302 - val_accuracy: 0.2327 - val_loss: 0.3511 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2408 - loss: 0.1029 - val_accuracy: 0.2332 - val_loss: 0.3429 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2417 - loss: 0.0862 - val_accuracy: 0.2340 - val_loss: 0.3340 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2427 - loss: 0.0716 - val_accuracy: 0.2344 - val_loss: 0.3323 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2430 - loss: 0.0629 - val_accuracy: 0.2344 - val_loss: 0.3323 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__all_on__drop0.2\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.1475 - loss: 2.9543 - val_accuracy: 0.1920 - val_loss: 0.9703 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.1998 - loss: 0.8080 - val_accuracy: 0.2123 - val_loss: 0.6751 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2192 - loss: 0.4873 - val_accuracy: 0.2230 - val_loss: 0.5047 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2287 - loss: 0.3110 - val_accuracy: 0.2277 - val_loss: 0.4323 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2338 - loss: 0.2225 - val_accuracy: 0.2300 - val_loss: 0.3962 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2368 - loss: 0.1723 - val_accuracy: 0.2313 - val_loss: 0.3780 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2384 - loss: 0.1440 - val_accuracy: 0.2325 - val_loss: 0.3651 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2400 - loss: 0.1172 - val_accuracy: 0.2329 - val_loss: 0.3568 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2410 - loss: 0.0998 - val_accuracy: 0.2335 - val_loss: 0.3521 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2416 - loss: 0.0895 - val_accuracy: 0.2338 - val_loss: 0.3496 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__all_on__drop0.4\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.1395 - loss: 3.0585 - val_accuracy: 0.1835 - val_loss: 1.1184 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.1870 - loss: 0.9824 - val_accuracy: 0.2036 - val_loss: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2075 - loss: 0.6557 - val_accuracy: 0.2141 - val_loss: 0.6487 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2167 - loss: 0.4971 - val_accuracy: 0.2206 - val_loss: 0.5454 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2229 - loss: 0.3919 - val_accuracy: 0.2236 - val_loss: 0.4889 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2265 - loss: 0.3181 - val_accuracy: 0.2263 - val_loss: 0.4529 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2301 - loss: 0.2682 - val_accuracy: 0.2290 - val_loss: 0.4193 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2325 - loss: 0.2277 - val_accuracy: 0.2299 - val_loss: 0.4051 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2339 - loss: 0.2086 - val_accuracy: 0.2307 - val_loss: 0.3918 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2357 - loss: 0.1829 - val_accuracy: 0.2312 - val_loss: 0.3845 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__all_on__drop0.6\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.1222 - loss: 3.2209 - val_accuracy: 0.1826 - val_loss: 1.1847 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1801 - loss: 1.1081 - val_accuracy: 0.1977 - val_loss: 0.8792 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1995 - loss: 0.8136 - val_accuracy: 0.2046 - val_loss: 0.7478 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.2074 - loss: 0.6631 - val_accuracy: 0.2136 - val_loss: 0.6578 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2122 - loss: 0.5695 - val_accuracy: 0.2172 - val_loss: 0.5869 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2161 - loss: 0.4957 - val_accuracy: 0.2209 - val_loss: 0.5456 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2192 - loss: 0.4397 - val_accuracy: 0.2221 - val_loss: 0.5088 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2221 - loss: 0.3945 - val_accuracy: 0.2239 - val_loss: 0.4871 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2236 - loss: 0.3608 - val_accuracy: 0.2248 - val_loss: 0.4767 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2250 - loss: 0.3373 - val_accuracy: 0.2250 - val_loss: 0.4682 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postlstm__drop0.05\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.1468 - loss: 2.9860 - val_accuracy: 0.1794 - val_loss: 1.2232 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1837 - loss: 1.1126 - val_accuracy: 0.1933 - val_loss: 0.9236 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2028 - loss: 0.8013 - val_accuracy: 0.2083 - val_loss: 0.6835 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2173 - loss: 0.5603 - val_accuracy: 0.2182 - val_loss: 0.5287 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2253 - loss: 0.4081 - val_accuracy: 0.2226 - val_loss: 0.4405 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2303 - loss: 0.3161 - val_accuracy: 0.2258 - val_loss: 0.3871 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2333 - loss: 0.2562 - val_accuracy: 0.2271 - val_loss: 0.3534 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2350 - loss: 0.2149 - val_accuracy: 0.2284 - val_loss: 0.3299 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2364 - loss: 0.1838 - val_accuracy: 0.2292 - val_loss: 0.3122 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2379 - loss: 0.1597 - val_accuracy: 0.2302 - val_loss: 0.2987 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postlstm__drop0.1\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.1459 - loss: 3.0120 - val_accuracy: 0.1787 - val_loss: 1.2165 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.1840 - loss: 1.1041 - val_accuracy: 0.1967 - val_loss: 0.9184 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2041 - loss: 0.7996 - val_accuracy: 0.2090 - val_loss: 0.6978 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2198 - loss: 0.5789 - val_accuracy: 0.2197 - val_loss: 0.5373 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2271 - loss: 0.4178 - val_accuracy: 0.2219 - val_loss: 0.4445 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2298 - loss: 0.3233 - val_accuracy: 0.2250 - val_loss: 0.3922 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.2329 - loss: 0.2626 - val_accuracy: 0.2271 - val_loss: 0.3576 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2349 - loss: 0.2199 - val_accuracy: 0.2283 - val_loss: 0.3328 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2367 - loss: 0.1872 - val_accuracy: 0.2295 - val_loss: 0.3146 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2382 - loss: 0.1617 - val_accuracy: 0.2304 - val_loss: 0.2998 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postlstm__drop0.2\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1469 - loss: 3.0400 - val_accuracy: 0.1872 - val_loss: 1.1740 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1919 - loss: 1.0520 - val_accuracy: 0.1988 - val_loss: 0.8449 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2079 - loss: 0.7319 - val_accuracy: 0.2149 - val_loss: 0.6272 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2228 - loss: 0.5199 - val_accuracy: 0.2209 - val_loss: 0.4935 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2276 - loss: 0.3880 - val_accuracy: 0.2229 - val_loss: 0.4183 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2304 - loss: 0.3054 - val_accuracy: 0.2264 - val_loss: 0.3714 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2338 - loss: 0.2480 - val_accuracy: 0.2287 - val_loss: 0.3392 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2361 - loss: 0.2082 - val_accuracy: 0.2296 - val_loss: 0.3159 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2377 - loss: 0.1754 - val_accuracy: 0.2307 - val_loss: 0.2984 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2389 - loss: 0.1505 - val_accuracy: 0.2316 - val_loss: 0.2855 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postlstm__drop0.4\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1386 - loss: 3.1936 - val_accuracy: 0.1759 - val_loss: 1.2738 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1796 - loss: 1.1930 - val_accuracy: 0.1927 - val_loss: 0.9718 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1967 - loss: 0.8929 - val_accuracy: 0.2033 - val_loss: 0.7769 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2092 - loss: 0.7006 - val_accuracy: 0.2132 - val_loss: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2196 - loss: 0.5527 - val_accuracy: 0.2195 - val_loss: 0.5287 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2252 - loss: 0.4476 - val_accuracy: 0.2221 - val_loss: 0.4629 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2279 - loss: 0.3739 - val_accuracy: 0.2239 - val_loss: 0.4197 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2295 - loss: 0.3263 - val_accuracy: 0.2256 - val_loss: 0.3880 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2315 - loss: 0.2855 - val_accuracy: 0.2269 - val_loss: 0.3662 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2330 - loss: 0.2530 - val_accuracy: 0.2279 - val_loss: 0.3499 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postlstm__drop0.6\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1290 - loss: 3.3624 - val_accuracy: 0.1697 - val_loss: 1.2931 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1731 - loss: 1.2554 - val_accuracy: 0.1864 - val_loss: 1.0536 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1842 - loss: 1.0196 - val_accuracy: 0.1919 - val_loss: 0.9107 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1932 - loss: 0.8734 - val_accuracy: 0.2055 - val_loss: 0.7585 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2068 - loss: 0.7112 - val_accuracy: 0.2150 - val_loss: 0.6153 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2161 - loss: 0.5807 - val_accuracy: 0.2200 - val_loss: 0.5231 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2212 - loss: 0.4916 - val_accuracy: 0.2211 - val_loss: 0.4693 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2240 - loss: 0.4256 - val_accuracy: 0.2221 - val_loss: 0.4338 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2262 - loss: 0.3754 - val_accuracy: 0.2234 - val_loss: 0.4097 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2278 - loss: 0.3444 - val_accuracy: 0.2257 - val_loss: 0.3904 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postdense__drop0.05\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.1522 - loss: 2.8819 - val_accuracy: 0.1924 - val_loss: 0.9776 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2025 - loss: 0.7734 - val_accuracy: 0.2176 - val_loss: 0.5999 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2259 - loss: 0.3980 - val_accuracy: 0.2264 - val_loss: 0.4343 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2348 - loss: 0.2229 - val_accuracy: 0.2302 - val_loss: 0.3726 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2390 - loss: 0.1485 - val_accuracy: 0.2322 - val_loss: 0.3447 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2413 - loss: 0.1083 - val_accuracy: 0.2337 - val_loss: 0.3287 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2422 - loss: 0.0807 - val_accuracy: 0.2341 - val_loss: 0.3208 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2432 - loss: 0.0644 - val_accuracy: 0.2345 - val_loss: 0.3135 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2439 - loss: 0.0528 - val_accuracy: 0.2349 - val_loss: 0.3127 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2441 - loss: 0.0459 - val_accuracy: 0.2350 - val_loss: 0.3113 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postdense__drop0.1\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.1520 - loss: 2.8775 - val_accuracy: 0.1941 - val_loss: 0.9438 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2040 - loss: 0.7487 - val_accuracy: 0.2139 - val_loss: 0.6186 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.2223 - loss: 0.4313 - val_accuracy: 0.2244 - val_loss: 0.4528 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2317 - loss: 0.2665 - val_accuracy: 0.2290 - val_loss: 0.3859 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2367 - loss: 0.1813 - val_accuracy: 0.2312 - val_loss: 0.3506 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2397 - loss: 0.1324 - val_accuracy: 0.2326 - val_loss: 0.3330 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.2410 - loss: 0.1029 - val_accuracy: 0.2333 - val_loss: 0.3254 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2420 - loss: 0.0845 - val_accuracy: 0.2336 - val_loss: 0.3226 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2428 - loss: 0.0712 - val_accuracy: 0.2339 - val_loss: 0.3219 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2434 - loss: 0.0598 - val_accuracy: 0.2340 - val_loss: 0.3262 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postdense__drop0.2\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.1461 - loss: 2.9757 - val_accuracy: 0.1858 - val_loss: 1.0753 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1955 - loss: 0.8736 - val_accuracy: 0.2129 - val_loss: 0.6543 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.2210 - loss: 0.4702 - val_accuracy: 0.2230 - val_loss: 0.4571 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.2304 - loss: 0.2755 - val_accuracy: 0.2286 - val_loss: 0.3850 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2360 - loss: 0.1878 - val_accuracy: 0.2313 - val_loss: 0.3498 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2387 - loss: 0.1380 - val_accuracy: 0.2323 - val_loss: 0.3315 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2402 - loss: 0.1115 - val_accuracy: 0.2330 - val_loss: 0.3288 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2411 - loss: 0.0913 - val_accuracy: 0.2338 - val_loss: 0.3213 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2422 - loss: 0.0765 - val_accuracy: 0.2341 - val_loss: 0.3182 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2428 - loss: 0.0644 - val_accuracy: 0.2343 - val_loss: 0.3186 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postdense__drop0.4\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.1439 - loss: 3.0353 - val_accuracy: 0.1838 - val_loss: 1.0908 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1907 - loss: 0.9231 - val_accuracy: 0.2066 - val_loss: 0.7329 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2135 - loss: 0.5715 - val_accuracy: 0.2193 - val_loss: 0.5489 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.2246 - loss: 0.3752 - val_accuracy: 0.2246 - val_loss: 0.4554 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.2310 - loss: 0.2698 - val_accuracy: 0.2287 - val_loss: 0.4074 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2346 - loss: 0.2117 - val_accuracy: 0.2305 - val_loss: 0.3789 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2368 - loss: 0.1729 - val_accuracy: 0.2316 - val_loss: 0.3601 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2387 - loss: 0.1402 - val_accuracy: 0.2330 - val_loss: 0.3488 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2400 - loss: 0.1198 - val_accuracy: 0.2333 - val_loss: 0.3437 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2407 - loss: 0.1016 - val_accuracy: 0.2336 - val_loss: 0.3448 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_postdense__drop0.6\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.1419 - loss: 3.1089 - val_accuracy: 0.1859 - val_loss: 1.1100 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1920 - loss: 0.9685 - val_accuracy: 0.2047 - val_loss: 0.7470 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2099 - loss: 0.6390 - val_accuracy: 0.2149 - val_loss: 0.6098 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2173 - loss: 0.4903 - val_accuracy: 0.2214 - val_loss: 0.5197 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2245 - loss: 0.3831 - val_accuracy: 0.2250 - val_loss: 0.4610 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.2289 - loss: 0.3052 - val_accuracy: 0.2271 - val_loss: 0.4247 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2318 - loss: 0.2589 - val_accuracy: 0.2291 - val_loss: 0.4018 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2339 - loss: 0.2238 - val_accuracy: 0.2300 - val_loss: 0.3896 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2351 - loss: 0.1990 - val_accuracy: 0.2309 - val_loss: 0.3772 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2363 - loss: 0.1748 - val_accuracy: 0.2317 - val_loss: 0.3683 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_only__drop0.05\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.1480 - loss: 2.9933 - val_accuracy: 0.1838 - val_loss: 1.1831 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1941 - loss: 1.0440 - val_accuracy: 0.1996 - val_loss: 0.8471 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2101 - loss: 0.7163 - val_accuracy: 0.2168 - val_loss: 0.6213 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2255 - loss: 0.4916 - val_accuracy: 0.2216 - val_loss: 0.4818 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2291 - loss: 0.3560 - val_accuracy: 0.2243 - val_loss: 0.4066 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2324 - loss: 0.2754 - val_accuracy: 0.2276 - val_loss: 0.3583 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2362 - loss: 0.2200 - val_accuracy: 0.2290 - val_loss: 0.3250 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2376 - loss: 0.1805 - val_accuracy: 0.2306 - val_loss: 0.3010 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2392 - loss: 0.1511 - val_accuracy: 0.2316 - val_loss: 0.2837 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2402 - loss: 0.1282 - val_accuracy: 0.2321 - val_loss: 0.2715 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_only__drop0.1\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.1469 - loss: 3.0283 - val_accuracy: 0.1759 - val_loss: 1.2341 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1833 - loss: 1.1176 - val_accuracy: 0.1887 - val_loss: 0.9713 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1998 - loss: 0.8461 - val_accuracy: 0.2072 - val_loss: 0.7311 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2166 - loss: 0.5972 - val_accuracy: 0.2182 - val_loss: 0.5724 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2251 - loss: 0.4425 - val_accuracy: 0.2217 - val_loss: 0.4762 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2287 - loss: 0.3433 - val_accuracy: 0.2236 - val_loss: 0.4154 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2319 - loss: 0.2757 - val_accuracy: 0.2269 - val_loss: 0.3731 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2354 - loss: 0.2252 - val_accuracy: 0.2288 - val_loss: 0.3425 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2373 - loss: 0.1862 - val_accuracy: 0.2300 - val_loss: 0.3192 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2386 - loss: 0.1557 - val_accuracy: 0.2308 - val_loss: 0.3031 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_only__drop0.2\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.1441 - loss: 3.0770 - val_accuracy: 0.1718 - val_loss: 1.2256 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1807 - loss: 1.1072 - val_accuracy: 0.1892 - val_loss: 0.9577 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1982 - loss: 0.8372 - val_accuracy: 0.2097 - val_loss: 0.7319 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2197 - loss: 0.5944 - val_accuracy: 0.2198 - val_loss: 0.5487 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2267 - loss: 0.4199 - val_accuracy: 0.2223 - val_loss: 0.4514 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2296 - loss: 0.3229 - val_accuracy: 0.2240 - val_loss: 0.3973 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2322 - loss: 0.2618 - val_accuracy: 0.2270 - val_loss: 0.3590 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2356 - loss: 0.2153 - val_accuracy: 0.2291 - val_loss: 0.3293 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2374 - loss: 0.1787 - val_accuracy: 0.2304 - val_loss: 0.3084 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2388 - loss: 0.1515 - val_accuracy: 0.2311 - val_loss: 0.2935 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_only__drop0.4\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.1448 - loss: 3.1114 - val_accuracy: 0.1831 - val_loss: 1.2282 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1903 - loss: 1.1112 - val_accuracy: 0.1949 - val_loss: 0.9339 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2022 - loss: 0.8140 - val_accuracy: 0.2068 - val_loss: 0.7264 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2178 - loss: 0.6017 - val_accuracy: 0.2190 - val_loss: 0.5696 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.2268 - loss: 0.4457 - val_accuracy: 0.2218 - val_loss: 0.4684 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2289 - loss: 0.3446 - val_accuracy: 0.2232 - val_loss: 0.4111 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2306 - loss: 0.2824 - val_accuracy: 0.2257 - val_loss: 0.3745 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2336 - loss: 0.2385 - val_accuracy: 0.2282 - val_loss: 0.3472 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2363 - loss: 0.2033 - val_accuracy: 0.2299 - val_loss: 0.3254 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2377 - loss: 0.1751 - val_accuracy: 0.2308 - val_loss: 0.3095 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__embed_only__drop0.6\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1426 - loss: 3.1620 - val_accuracy: 0.1835 - val_loss: 1.2240 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1908 - loss: 1.1028 - val_accuracy: 0.1967 - val_loss: 0.9116 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2050 - loss: 0.7954 - val_accuracy: 0.2090 - val_loss: 0.7032 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2188 - loss: 0.5856 - val_accuracy: 0.2188 - val_loss: 0.5521 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2254 - loss: 0.4385 - val_accuracy: 0.2221 - val_loss: 0.4598 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2295 - loss: 0.3414 - val_accuracy: 0.2249 - val_loss: 0.3998 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2323 - loss: 0.2801 - val_accuracy: 0.2265 - val_loss: 0.3639 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2340 - loss: 0.2365 - val_accuracy: 0.2284 - val_loss: 0.3380 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2361 - loss: 0.2028 - val_accuracy: 0.2296 - val_loss: 0.3176 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2373 - loss: 0.1759 - val_accuracy: 0.2303 - val_loss: 0.3033 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postlstm_only__drop0.05\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.1477 - loss: 3.0187 - val_accuracy: 0.1758 - val_loss: 1.1962 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1843 - loss: 1.0747 - val_accuracy: 0.1941 - val_loss: 0.8943 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2040 - loss: 0.7672 - val_accuracy: 0.2141 - val_loss: 0.6460 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2220 - loss: 0.5209 - val_accuracy: 0.2195 - val_loss: 0.5049 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2267 - loss: 0.3859 - val_accuracy: 0.2229 - val_loss: 0.4294 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2308 - loss: 0.3026 - val_accuracy: 0.2252 - val_loss: 0.3790 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2337 - loss: 0.2437 - val_accuracy: 0.2274 - val_loss: 0.3445 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2365 - loss: 0.2013 - val_accuracy: 0.2300 - val_loss: 0.3191 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2384 - loss: 0.1682 - val_accuracy: 0.2308 - val_loss: 0.3000 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2396 - loss: 0.1442 - val_accuracy: 0.2313 - val_loss: 0.2869 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postlstm_only__drop0.1\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1480 - loss: 3.0061 - val_accuracy: 0.1777 - val_loss: 1.1981 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1860 - loss: 1.0807 - val_accuracy: 0.1936 - val_loss: 0.8836 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2048 - loss: 0.7603 - val_accuracy: 0.2145 - val_loss: 0.6377 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2228 - loss: 0.5176 - val_accuracy: 0.2216 - val_loss: 0.4839 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2290 - loss: 0.3693 - val_accuracy: 0.2242 - val_loss: 0.4066 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2315 - loss: 0.2861 - val_accuracy: 0.2267 - val_loss: 0.3603 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2345 - loss: 0.2325 - val_accuracy: 0.2286 - val_loss: 0.3281 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2369 - loss: 0.1911 - val_accuracy: 0.2299 - val_loss: 0.3045 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2384 - loss: 0.1620 - val_accuracy: 0.2310 - val_loss: 0.2869 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2396 - loss: 0.1386 - val_accuracy: 0.2318 - val_loss: 0.2748 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postlstm_only__drop0.2\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1473 - loss: 3.0458 - val_accuracy: 0.1833 - val_loss: 1.1792 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1903 - loss: 1.0527 - val_accuracy: 0.1977 - val_loss: 0.8414 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2077 - loss: 0.7275 - val_accuracy: 0.2161 - val_loss: 0.6263 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2230 - loss: 0.5229 - val_accuracy: 0.2210 - val_loss: 0.4919 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2280 - loss: 0.3891 - val_accuracy: 0.2233 - val_loss: 0.4168 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2306 - loss: 0.3048 - val_accuracy: 0.2254 - val_loss: 0.3733 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2331 - loss: 0.2522 - val_accuracy: 0.2276 - val_loss: 0.3420 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2353 - loss: 0.2140 - val_accuracy: 0.2288 - val_loss: 0.3197 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2368 - loss: 0.1843 - val_accuracy: 0.2302 - val_loss: 0.3022 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.2382 - loss: 0.1583 - val_accuracy: 0.2310 - val_loss: 0.2893 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postlstm_only__drop0.4\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1437 - loss: 3.1225 - val_accuracy: 0.1792 - val_loss: 1.2422 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.1781 - loss: 1.1632 - val_accuracy: 0.1949 - val_loss: 0.9247 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2015 - loss: 0.8253 - val_accuracy: 0.2128 - val_loss: 0.6796 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2192 - loss: 0.5870 - val_accuracy: 0.2203 - val_loss: 0.5274 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2263 - loss: 0.4404 - val_accuracy: 0.2230 - val_loss: 0.4375 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2294 - loss: 0.3446 - val_accuracy: 0.2257 - val_loss: 0.3855 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2323 - loss: 0.2832 - val_accuracy: 0.2282 - val_loss: 0.3507 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2350 - loss: 0.2362 - val_accuracy: 0.2296 - val_loss: 0.3272 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2363 - loss: 0.2086 - val_accuracy: 0.2305 - val_loss: 0.3097 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2376 - loss: 0.1808 - val_accuracy: 0.2313 - val_loss: 0.2970 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postlstm_only__drop0.6\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.1419 - loss: 3.1569 - val_accuracy: 0.1844 - val_loss: 1.1982 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.1812 - loss: 1.1515 - val_accuracy: 0.1956 - val_loss: 0.9229 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1979 - loss: 0.8813 - val_accuracy: 0.2068 - val_loss: 0.7357 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2096 - loss: 0.6904 - val_accuracy: 0.2161 - val_loss: 0.5889 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2194 - loss: 0.5405 - val_accuracy: 0.2212 - val_loss: 0.4907 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2250 - loss: 0.4392 - val_accuracy: 0.2234 - val_loss: 0.4295 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2283 - loss: 0.3669 - val_accuracy: 0.2251 - val_loss: 0.3928 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2300 - loss: 0.3163 - val_accuracy: 0.2275 - val_loss: 0.3654 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2323 - loss: 0.2771 - val_accuracy: 0.2294 - val_loss: 0.3447 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2335 - loss: 0.2519 - val_accuracy: 0.2300 - val_loss: 0.3305 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postdense_only__drop0.05\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.1475 - loss: 2.9659 - val_accuracy: 0.1894 - val_loss: 1.0167 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2008 - loss: 0.7962 - val_accuracy: 0.2171 - val_loss: 0.6097 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2258 - loss: 0.4029 - val_accuracy: 0.2261 - val_loss: 0.4379 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2338 - loss: 0.2235 - val_accuracy: 0.2297 - val_loss: 0.3794 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2385 - loss: 0.1475 - val_accuracy: 0.2317 - val_loss: 0.3532 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.2407 - loss: 0.1061 - val_accuracy: 0.2327 - val_loss: 0.3420 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2420 - loss: 0.0840 - val_accuracy: 0.2332 - val_loss: 0.3419 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2429 - loss: 0.0667 - val_accuracy: 0.2339 - val_loss: 0.3388 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2437 - loss: 0.0541 - val_accuracy: 0.2341 - val_loss: 0.3342 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2441 - loss: 0.0454 - val_accuracy: 0.2343 - val_loss: 0.3324 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postdense_only__drop0.1\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.1496 - loss: 2.9109 - val_accuracy: 0.1903 - val_loss: 1.0132 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.2003 - loss: 0.8023 - val_accuracy: 0.2131 - val_loss: 0.6213 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2231 - loss: 0.4227 - val_accuracy: 0.2260 - val_loss: 0.4367 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2331 - loss: 0.2401 - val_accuracy: 0.2298 - val_loss: 0.3672 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2380 - loss: 0.1580 - val_accuracy: 0.2319 - val_loss: 0.3356 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2402 - loss: 0.1138 - val_accuracy: 0.2327 - val_loss: 0.3248 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2418 - loss: 0.0885 - val_accuracy: 0.2336 - val_loss: 0.3199 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2426 - loss: 0.0720 - val_accuracy: 0.2338 - val_loss: 0.3188 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2434 - loss: 0.0582 - val_accuracy: 0.2343 - val_loss: 0.3117 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2438 - loss: 0.0496 - val_accuracy: 0.2344 - val_loss: 0.3157 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postdense_only__drop0.2\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.1516 - loss: 2.8867 - val_accuracy: 0.1930 - val_loss: 0.9734 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2025 - loss: 0.7632 - val_accuracy: 0.2141 - val_loss: 0.6156 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2228 - loss: 0.4124 - val_accuracy: 0.2267 - val_loss: 0.4449 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2337 - loss: 0.2404 - val_accuracy: 0.2299 - val_loss: 0.3808 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2379 - loss: 0.1639 - val_accuracy: 0.2315 - val_loss: 0.3572 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2394 - loss: 0.1218 - val_accuracy: 0.2326 - val_loss: 0.3468 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2410 - loss: 0.0978 - val_accuracy: 0.2332 - val_loss: 0.3392 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.2419 - loss: 0.0811 - val_accuracy: 0.2333 - val_loss: 0.3346 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.2426 - loss: 0.0692 - val_accuracy: 0.2337 - val_loss: 0.3328 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2434 - loss: 0.0571 - val_accuracy: 0.2343 - val_loss: 0.3276 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postdense_only__drop0.4\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.1474 - loss: 2.9090 - val_accuracy: 0.1894 - val_loss: 1.0056 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2003 - loss: 0.8173 - val_accuracy: 0.2115 - val_loss: 0.6580 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2185 - loss: 0.4830 - val_accuracy: 0.2225 - val_loss: 0.4876 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2294 - loss: 0.3051 - val_accuracy: 0.2279 - val_loss: 0.4098 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2349 - loss: 0.2130 - val_accuracy: 0.2304 - val_loss: 0.3770 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2375 - loss: 0.1658 - val_accuracy: 0.2319 - val_loss: 0.3603 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2396 - loss: 0.1304 - val_accuracy: 0.2326 - val_loss: 0.3496 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2412 - loss: 0.1046 - val_accuracy: 0.2336 - val_loss: 0.3412 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.2419 - loss: 0.0875 - val_accuracy: 0.2336 - val_loss: 0.3418 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2427 - loss: 0.0746 - val_accuracy: 0.2342 - val_loss: 0.3418 - learning_rate: 0.0010\n",
            "\n",
            "==============================================================================================================\n",
            "Entrenando lstm_64_emb512__postdense_only__drop0.6\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.1409 - loss: 3.0132 - val_accuracy: 0.1857 - val_loss: 1.0843 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1902 - loss: 0.9347 - val_accuracy: 0.2076 - val_loss: 0.7139 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2143 - loss: 0.5703 - val_accuracy: 0.2207 - val_loss: 0.5369 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2247 - loss: 0.3883 - val_accuracy: 0.2243 - val_loss: 0.4566 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2300 - loss: 0.2908 - val_accuracy: 0.2284 - val_loss: 0.4099 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2336 - loss: 0.2299 - val_accuracy: 0.2303 - val_loss: 0.3809 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2360 - loss: 0.1840 - val_accuracy: 0.2310 - val_loss: 0.3717 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2381 - loss: 0.1562 - val_accuracy: 0.2323 - val_loss: 0.3573 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2393 - loss: 0.1300 - val_accuracy: 0.2332 - val_loss: 0.3522 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2401 - loss: 0.1160 - val_accuracy: 0.2335 - val_loss: 0.3479 - learning_rate: 0.0010\n",
            "\n",
            "Resumen LSTM64 (emb=512) SIN dropout interno:\n",
            "                                    model  accuracy  macro_precision  macro_recall  macro_f1  weighted_precision  weighted_recall  weighted_f1  support_total\n",
            "         lstm_64_emb512__all_on__drop0.05    0.8007           0.8947        0.7325    0.7315              0.8483           0.8007       0.7242           9010\n",
            "          lstm_64_emb512__all_on__drop0.1    0.8027           0.8696        0.7647    0.7498              0.8481           0.8027       0.7260           9010\n",
            "          lstm_64_emb512__all_on__drop0.2    0.8001           0.8930        0.7156    0.7174              0.8467           0.8001       0.7234           9010\n",
            "          lstm_64_emb512__all_on__drop0.4    0.7956           0.8594        0.5616    0.5304              0.9727           0.7956       0.7906           9010\n",
            "          lstm_64_emb512__all_on__drop0.6    0.7776           0.8510        0.3212    0.2994              0.9553           0.7776       0.7646           9010\n",
            "     lstm_64_emb512__embed_only__drop0.05    0.7974           0.8919        0.5767    0.5625              0.9735           0.7974       0.7915           9010\n",
            "      lstm_64_emb512__embed_only__drop0.1    0.7932           0.8767        0.5200    0.4910              0.9725           0.7932       0.7864           9010\n",
            "      lstm_64_emb512__embed_only__drop0.2    0.7929           0.8589        0.5219    0.4850              0.9716           0.7929       0.7859           9010\n",
            "      lstm_64_emb512__embed_only__drop0.4    0.7910           0.8593        0.5001    0.4669              0.9687           0.7910       0.7836           9010\n",
            "      lstm_64_emb512__embed_only__drop0.6    0.7912           0.8551        0.4836    0.4528              0.9668           0.7912       0.7836           9010\n",
            "lstm_64_emb512__embed_postdense__drop0.05    0.8014           0.8867        0.7736    0.7664              0.8476           0.8014       0.7252           9010\n",
            " lstm_64_emb512__embed_postdense__drop0.1    0.8018           0.8845        0.7389    0.7198              0.8489           0.8018       0.7256           9010\n",
            " lstm_64_emb512__embed_postdense__drop0.2    0.8010           0.8588        0.7160    0.6851              0.8471           0.8010       0.7243           9010\n",
            " lstm_64_emb512__embed_postdense__drop0.4    0.7982           0.8636        0.6816    0.6645              0.8434           0.7982       0.7206           9010\n",
            " lstm_64_emb512__embed_postdense__drop0.6    0.7940           0.8677        0.5589    0.5402              0.8421           0.7940       0.7135           9010\n",
            " lstm_64_emb512__embed_postlstm__drop0.05    0.7911           0.8455        0.5091    0.4752              0.9683           0.7911       0.7843           9010\n",
            "  lstm_64_emb512__embed_postlstm__drop0.1    0.7936           0.8374        0.5309    0.4940              0.9675           0.7936       0.7841           9010\n",
            "  lstm_64_emb512__embed_postlstm__drop0.2    0.7960           0.8828        0.5391    0.5149              0.9696           0.7960       0.7869           9010\n",
            "  lstm_64_emb512__embed_postlstm__drop0.4    0.7819           0.8690        0.4079    0.3540              0.9636           0.7819       0.7697           9010\n",
            "  lstm_64_emb512__embed_postlstm__drop0.6    0.7757           0.8693        0.3419    0.3111              0.9575           0.7757       0.7618           9010\n",
            " lstm_64_emb512__postdense_only__drop0.05    0.8011           0.8868        0.7757    0.7728              0.8478           0.8011       0.7253           9010\n",
            "  lstm_64_emb512__postdense_only__drop0.1    0.7990           0.8458        0.7236    0.7058              0.8444           0.7990       0.7223           9010\n",
            "  lstm_64_emb512__postdense_only__drop0.2    0.8028           0.8878        0.7802    0.7612              0.8494           0.8028       0.7268           9010\n",
            "  lstm_64_emb512__postdense_only__drop0.4    0.7993           0.8460        0.6597    0.6469              0.8465           0.7993       0.7218           9010\n",
            "  lstm_64_emb512__postdense_only__drop0.6    0.7977           0.8504        0.6292    0.6233              0.8439           0.7977       0.7201           9010\n",
            "  lstm_64_emb512__postlstm_only__drop0.05    0.7939           0.8838        0.5503    0.5277              0.9689           0.7939       0.7851           9010\n",
            "   lstm_64_emb512__postlstm_only__drop0.1    0.7951           0.8684        0.5561    0.5316              0.9721           0.7951       0.7886           9010\n",
            "   lstm_64_emb512__postlstm_only__drop0.2    0.7961           0.8794        0.5349    0.5085              0.9698           0.7961       0.7875           9010\n",
            "   lstm_64_emb512__postlstm_only__drop0.4    0.7946           0.8883        0.5227    0.4931              0.9730           0.7946       0.7885           9010\n",
            "   lstm_64_emb512__postlstm_only__drop0.6    0.7912           0.8844        0.4941    0.4583              0.9664           0.7912       0.7805           9010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DESBALANCEIG DE CLASSES"
      ],
      "metadata": {
        "id": "Z1zCIK1C6o7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombres de clase\n",
        "try:\n",
        "    label_names = list(label_encoder.classes_) + ['<pad>']\n",
        "except NameError:\n",
        "    label_names = [f\"cls_{i}\" for i in range(num_classes-1)] + ['<pad>']\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def freq_table(counts_vec, label_names):\n",
        "    df = pd.DataFrame({\n",
        "        \"class_id\": np.arange(len(counts_vec)),\n",
        "        \"class_name\": label_names,\n",
        "        \"count\": counts_vec\n",
        "    })\n",
        "    df[\"pct\"] = df[\"count\"] / df[\"count\"].sum()\n",
        "    return df.sort_values(\"count\", ascending=False)\n",
        "\n",
        "df_freq = freq_table(counts_all, label_names)\n",
        "print(df_freq.head(20).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbLJ2i-C7XwW",
        "outputId": "0bf98212-8245-4837-fe67-7d7fe217fc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " class_id                  class_name  count      pct\n",
            "      119                       <pad> 204065 0.757030\n",
            "      118                           O  41449 0.153765\n",
            "       72           B-toloc.city_name   5036 0.018682\n",
            "       45         B-fromloc.city_name   5019 0.018619\n",
            "      115           I-toloc.city_name   1359 0.005042\n",
            "       24      B-depart_date.day_name   1094 0.004058\n",
            "      103         I-fromloc.city_name    867 0.003216\n",
            "        2              B-airline_name    800 0.002968\n",
            "       31 B-depart_time.period_of_day    716 0.002656\n",
            "       77              I-airline_name    489 0.001814\n",
            "       25    B-depart_date.day_number    448 0.001662\n",
            "       26    B-depart_date.month_name    435 0.001614\n",
            "       33          B-depart_time.time    423 0.001569\n",
            "       61                B-round_trip    418 0.001551\n",
            "      110                I-round_trip    406 0.001506\n",
            "       34 B-depart_time.time_relative    388 0.001439\n",
            "       19             B-cost_relative    381 0.001413\n",
            "       39                B-flight_mod    352 0.001306\n",
            "       94          I-depart_time.time    347 0.001287\n",
            "       16                 B-city_name    278 0.001031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Configuraci√≥ b√†sica\n",
        "tf.random.set_seed(7)\n",
        "np.random.seed(7)\n",
        "\n",
        "max_len     = int(train_pad_sequences.shape[1])\n",
        "vocab_size  = int(np.max(train_pad_sequences)) + 1\n",
        "num_classes = int(train_labels_one_hot.shape[-1])   # inclou <pad>\n",
        "embedding_dim = 256\n",
        "\n",
        "pad_token_id_inputs = 0\n",
        "pad_label_id        = num_classes - 1\n",
        "\n",
        "try:\n",
        "    len_test_sequences\n",
        "except NameError:\n",
        "    len_test_sequences = np.sum(test_pad_sequences != pad_token_id_inputs, axis=1).tolist()\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.5),\n",
        "]\n",
        "\n",
        "# Funcions de m√®triques i resum\n",
        "def preds_to_index(preds_or_oh, seq_lens):\n",
        "    idx = []\n",
        "    for p, L in zip(preds_or_oh, seq_lens):\n",
        "        idx.extend(np.argmax(p[:int(L)], axis=-1))\n",
        "    return idx\n",
        "\n",
        "def macro_table_row(name, y_true_oh, y_pred_proba, seq_lens):\n",
        "    \"\"\"Crea una fila amb les m√®triques macro i ponderades.\"\"\"\n",
        "    y_true_idx = preds_to_index(y_true_oh, seq_lens)\n",
        "    y_pred_idx = preds_to_index(y_pred_proba, seq_lens)\n",
        "    rep = classification_report(y_true_idx, y_pred_idx, output_dict=True, zero_division=0.0)\n",
        "    return {\n",
        "        \"modelo\": name,\n",
        "        \"acc\": rep.get(\"accuracy\", 0.0),\n",
        "        \"prec_macro\": rep[\"macro avg\"][\"precision\"],\n",
        "        \"rec_macro\": rep[\"macro avg\"][\"recall\"],\n",
        "        \"f1_macro\": rep[\"macro avg\"][\"f1-score\"],\n",
        "        \"prec_weight\": rep[\"weighted avg\"][\"precision\"],\n",
        "        \"rec_weight\": rep[\"weighted avg\"][\"recall\"],\n",
        "        \"f1_weight\": rep[\"weighted avg\"][\"f1-score\"],\n",
        "    }\n",
        "\n",
        "def print_results_table(rows):\n",
        "    \"\"\"Mostra la taula resum dels resultats.\"\"\"\n",
        "    header = f'{\"modelo\":28s}  acc    P_mac  R_mac  F1_mac  P_wgt  R_wgt  F1_wgt'\n",
        "    print(\"\\n\" + header)\n",
        "    print(\"-\" * len(header))\n",
        "    for r in rows:\n",
        "        print(f'{r[\"modelo\"]:28s}  {r[\"acc\"]:.4f}  {r[\"prec_macro\"]:.4f}  {r[\"rec_macro\"]:.4f}  {r[\"f1_macro\"]:.4f}  {r[\"prec_weight\"]:.4f}  {r[\"rec_weight\"]:.4f}  {r[\"f1_weight\"]:.4f}')\n",
        "\n",
        "# Ponderaci√≥ de classes i creaci√≥ de pesos per token\n",
        "def build_token_weights(x_pad, y_ids, cw_vec, pad_id=0):\n",
        "    \"\"\"Genera pesos per token segons la seva classe (0 per <pad>).\"\"\"\n",
        "    mask_no_pad = (x_pad != pad_id).astype(np.float32)\n",
        "    return mask_no_pad * cw_vec[y_ids]\n",
        "\n",
        "train_y_ids = np.argmax(train_labels_one_hot, axis=-1)\n",
        "val_y_ids   = np.argmax(val_labels_one_hot, axis=-1)\n",
        "test_y_ids  = np.argmax(test_labels_one_hot, axis=-1)\n",
        "\n",
        "mask_train_flat = (train_pad_sequences.flatten() != pad_token_id_inputs)\n",
        "valid_flat_y = train_y_ids.flatten()[mask_train_flat]\n",
        "\n",
        "present_classes = np.unique(valid_flat_y)\n",
        "cw_present = compute_class_weight('balanced', classes=present_classes, y=valid_flat_y).astype(np.float32)\n",
        "\n",
        "cw_full = np.ones(num_classes, dtype=np.float32)\n",
        "cw_full[present_classes] = cw_present\n",
        "cw_full[present_classes] = np.sqrt(cw_full[present_classes])\n",
        "cw_full[present_classes] = np.clip(cw_full[present_classes], 0.5, 5.0)\n",
        "cw_full[pad_label_id] = 0.0\n",
        "\n",
        "train_sw = build_token_weights(train_pad_sequences, train_y_ids, cw_full, pad_id=pad_token_id_inputs)\n",
        "val_sw   = build_token_weights(val_pad_sequences,   val_y_ids,   cw_full, pad_id=pad_token_id_inputs)\n",
        "test_sw  = build_token_weights(test_pad_sequences,  test_y_ids,  cw_full, pad_id=pad_token_id_inputs)\n",
        "\n",
        "print(f\"[train_sw] min:{train_sw.min():.4f} max:{train_sw.max():.4f} mean:{train_sw.mean():.4f}\")\n",
        "print(f\"[val_sw]   min:{val_sw.min():.4f} max:{val_sw.max():.4f} mean:{val_sw.mean():.4f}\")\n",
        "print(f\"[test_sw]  min:{test_sw.min():.4f} max:{test_sw.max():.4f} mean:{test_sw.mean():.4f}\")\n",
        "\n",
        "# Model Transformer\n",
        "def build_transformer(name, num_heads=4, ff_dim=1024, depth=2, rate=0.1):\n",
        "    \"\"\"Construeix un model Transformer senzill per seq√º√®ncies etiquetades.\"\"\"\n",
        "    inp = keras.Input(shape=(max_len,), dtype=\"int32\")\n",
        "    x = TokenAndPositionEmbedding(maxlen=max_len, vocab_size=vocab_size, embed_dim=embedding_dim)(inp)\n",
        "    for _ in range(depth):\n",
        "        x = TransformerBlock(embed_dim=embedding_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate)(x)\n",
        "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
        "    m = keras.Model(inp, out, name=name)\n",
        "    m.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return m\n",
        "\n",
        "# Entrenament i resultats\n",
        "experiments = [\n",
        "    (\"trf_base_m_h4_d2_ff1024\", build_transformer(\"trf_base_m_h4_d2_ff1024\", num_heads=4, ff_dim=1024, depth=2, rate=0.1)),\n",
        "    (\"trf_base_h_h8_d2_ff1024\", build_transformer(\"trf_base_h_h8_d2_ff1024\", num_heads=8, ff_dim=1024, depth=2, rate=0.1)),\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for name, model in experiments:\n",
        "    print(f\"\\n=== Entrenant {name} (emb=512, amb pesos per token) ===\")\n",
        "    model.fit(\n",
        "        train_pad_sequences, train_labels_one_hot,\n",
        "        sample_weight=train_sw,\n",
        "        validation_data=(val_pad_sequences, val_labels_one_hot, val_sw),\n",
        "        epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=1\n",
        "    )\n",
        "    _ = model.evaluate(test_pad_sequences, test_labels_one_hot, sample_weight=test_sw, verbose=0)\n",
        "    preds = model.predict(test_pad_sequences, batch_size=batch_size, verbose=0)\n",
        "    rows.append(macro_table_row(name, test_labels_one_hot, preds, len_test_sequences))\n",
        "\n",
        "print_results_table(rows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIKy4reFyuIt",
        "outputId": "9db9b668-1cac-48cc-9f97-14729b12cd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train_sw] min:0.0000 max:5.0000 mean:0.1772\n",
            "[val_sw]   min:0.0000   max:5.0000   mean:0.1740\n",
            "[test_sw]  min:0.0000  max:5.0000  mean:0.1656\n",
            "\n",
            "=== Entrenando trf_base_m_h4_d2_ff1024 (emb=512, token sample_weight) ===\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - accuracy: 0.1859 - loss: 0.3396 - val_accuracy: 0.2148 - val_loss: 0.1397 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2252 - loss: 0.0775 - val_accuracy: 0.2244 - val_loss: 0.1204 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.2343 - loss: 0.0472 - val_accuracy: 0.2232 - val_loss: 0.1182 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2355 - loss: 0.0401 - val_accuracy: 0.2286 - val_loss: 0.1058 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2386 - loss: 0.0315 - val_accuracy: 0.2302 - val_loss: 0.1064 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2406 - loss: 0.0227 - val_accuracy: 0.2287 - val_loss: 0.1047 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2399 - loss: 0.0253 - val_accuracy: 0.2303 - val_loss: 0.1002 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.2414 - loss: 0.0203 - val_accuracy: 0.2310 - val_loss: 0.1006 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2413 - loss: 0.0190 - val_accuracy: 0.2276 - val_loss: 0.1219 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2416 - loss: 0.0172 - val_accuracy: 0.2330 - val_loss: 0.1038 - learning_rate: 5.0000e-04\n",
            "\n",
            "=== Entrenando trf_base_h_h8_d2_ff1024 (emb=512, token sample_weight) ===\n",
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 99ms/step - accuracy: 0.1898 - loss: 0.3455 - val_accuracy: 0.2181 - val_loss: 0.1343 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.2262 - loss: 0.0770 - val_accuracy: 0.2227 - val_loss: 0.1220 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2334 - loss: 0.0493 - val_accuracy: 0.2262 - val_loss: 0.1190 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2365 - loss: 0.0383 - val_accuracy: 0.2263 - val_loss: 0.1132 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2367 - loss: 0.0352 - val_accuracy: 0.2270 - val_loss: 0.1136 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.2374 - loss: 0.0330 - val_accuracy: 0.2261 - val_loss: 0.1183 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2393 - loss: 0.0260 - val_accuracy: 0.2320 - val_loss: 0.0998 - learning_rate: 5.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2427 - loss: 0.0129 - val_accuracy: 0.2318 - val_loss: 0.1031 - learning_rate: 5.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.2435 - loss: 0.0095 - val_accuracy: 0.2330 - val_loss: 0.1005 - learning_rate: 5.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.2450 - loss: 0.0054 - val_accuracy: 0.2337 - val_loss: 0.1018 - learning_rate: 2.5000e-04\n",
            "\n",
            "modelo                        acc    P_mac  R_mac  F1_mac  P_wgt  R_wgt  F1_wgt\n",
            "-------------------------------------------------------------------------------\n",
            "trf_base_m_h4_d2_ff1024       0.7938  0.4844  0.5936  0.4898  0.7819  0.7938  0.7823\n",
            "trf_base_h_h8_d2_ff1024       0.7940  0.3990  0.5750  0.4327  0.7660  0.7940  0.7751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Bidirectional, TimeDistributed, Dense\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# =========================\n",
        "# 0) Setup b√†sic\n",
        "# =========================\n",
        "tf.random.set_seed(7)\n",
        "np.random.seed(7)\n",
        "\n",
        "max_len     = int(train_pad_sequences.shape[1])\n",
        "vocab_size  = int(np.max(train_pad_sequences)) + 1\n",
        "num_classes = int(train_labels_one_hot.shape[-1])\n",
        "embedding_dim = 256\n",
        "\n",
        "pad_token_id_inputs = 0             # padding a les seq√º√®ncies d'entrada\n",
        "pad_label_id        = num_classes-1 # <pad> √©s la darrera classe al one-hot\n",
        "\n",
        "try:\n",
        "    len_test_sequences\n",
        "except NameError:\n",
        "    len_test_sequences = np.sum(test_pad_sequences != pad_token_id_inputs, axis=1).tolist()\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.5),\n",
        "]\n",
        "\n",
        "# =========================\n",
        "# 1) Utilitats\n",
        "# =========================\n",
        "def preds_to_index(preds_or_oh, seq_lens):\n",
        "    idx = []\n",
        "    for p, L in zip(preds_or_oh, seq_lens):\n",
        "        idx.extend(np.argmax(p[:int(L)], axis=-1))\n",
        "    return idx\n",
        "\n",
        "def macro_table_row(name, y_true_oh, y_pred_proba, seq_lens):\n",
        "    y_true_idx = preds_to_index(y_true_oh,  seq_lens)\n",
        "    y_pred_idx = preds_to_index(y_pred_proba, seq_lens)\n",
        "    rep = classification_report(y_true_idx, y_pred_idx, output_dict=True, zero_division=0.0)\n",
        "    return {\n",
        "        \"modelo\": name,\n",
        "        \"acc\":    rep.get(\"accuracy\", 0.0),\n",
        "        \"prec_macro\":  rep[\"macro avg\"][\"precision\"],\n",
        "        \"rec_macro\":   rep[\"macro avg\"][\"recall\"],\n",
        "        \"f1_macro\":    rep[\"macro avg\"][\"f1-score\"],\n",
        "        \"prec_weight\": rep[\"weighted avg\"][\"precision\"],\n",
        "        \"rec_weight\":  rep[\"weighted avg\"][\"recall\"],\n",
        "        \"f1_weight\":   rep[\"weighted avg\"][\"f1-score\"],\n",
        "    }\n",
        "\n",
        "def print_results_table(rows):\n",
        "    header = f'{\"modelo\":28s}  acc    P_mac  R_mac  F1_mac  P_wgt  R_wgt  F1_wgt'\n",
        "    print(\"\\n\" + header)\n",
        "    print(\"-\"*len(header))\n",
        "    for r in rows:\n",
        "        print(f'{r[\"modelo\"]:28s}  {r[\"acc\"]:.4f}  {r[\"prec_macro\"]:.4f}  {r[\"rec_macro\"]:.4f}  {r[\"f1_macro\"]:.4f}  {r[\"prec_weight\"]:.4f}  {r[\"rec_weight\"]:.4f}  {r[\"f1_weight\"]:.4f}')\n",
        "\n",
        "# =========================\n",
        "# 2) Pesos per classe (NOM√âS TRAIN) -> sample_weight per token\n",
        "# =========================\n",
        "def build_token_weights(x_pad, y_ids, cw_vec, pad_id=0):\n",
        "    mask_no_pad = (x_pad != pad_id).astype(np.float32)\n",
        "    return mask_no_pad * cw_vec[y_ids]\n",
        "\n",
        "train_y_ids = np.argmax(train_labels_one_hot, axis=-1)\n",
        "val_y_ids   = np.argmax(val_labels_one_hot,   axis=-1)\n",
        "test_y_ids  = np.argmax(test_labels_one_hot,  axis=-1)\n",
        "\n",
        "mask_train_flat = (train_pad_sequences.flatten() != pad_token_id_inputs)\n",
        "valid_flat_y    = train_y_ids.flatten()[mask_train_flat]\n",
        "\n",
        "present_classes = np.unique(valid_flat_y)\n",
        "cw_present = compute_class_weight(class_weight='balanced', classes=present_classes, y=valid_flat_y).astype(np.float32)\n",
        "\n",
        "cw_full = np.ones(num_classes, dtype=np.float32)\n",
        "cw_full[present_classes] = cw_present\n",
        "cw_full[present_classes] = np.sqrt(cw_full[present_classes])              # suavitza extrems\n",
        "cw_full[present_classes] = np.clip(cw_full[present_classes], 0.5, 5.0)    # evita pesos desbocats\n",
        "cw_full[pad_label_id] = 0.0                                               # <pad> no compta\n",
        "\n",
        "train_sw = build_token_weights(train_pad_sequences, train_y_ids, cw_full, pad_id=pad_token_id_inputs)\n",
        "val_sw   = build_token_weights(val_pad_sequences,   val_y_ids,   cw_full, pad_id=pad_token_id_inputs)\n",
        "test_sw  = build_token_weights(test_pad_sequences,  test_y_ids,  cw_full, pad_id=pad_token_id_inputs)\n",
        "\n",
        "# =========================\n",
        "# 3) Constructors BiLSTM128 i BiGRU128 per token\n",
        "# =========================\n",
        "def build_bilstm128(name=\"bilstm_128_emb256\"):\n",
        "    inp = keras.Input(shape=(max_len,), dtype=\"int32\")\n",
        "    x = Embedding(vocab_size, embedding_dim, input_length=max_len, mask_zero=True)(inp)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    out = TimeDistributed(Dense(num_classes, activation=\"softmax\"))(x)\n",
        "    m = keras.Model(inp, out, name=name)\n",
        "    m.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return m\n",
        "\n",
        "def build_bigru128(name=\"bigru_128_emb256\"):\n",
        "    inp = keras.Input(shape=(max_len,), dtype=\"int32\")\n",
        "    x = Embedding(vocab_size, embedding_dim, input_length=max_len, mask_zero=True)(inp)\n",
        "    x = Bidirectional(GRU(128, return_sequences=True))(x)\n",
        "    out = TimeDistributed(Dense(num_classes, activation=\"softmax\"))(x)\n",
        "    m = keras.Model(inp, out, name=name)\n",
        "    m.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return m\n",
        "\n",
        "# =========================\n",
        "# 4) Entrenament + Avaluaci√≥ amb sample_weight per a ambd√≥s models\n",
        "# =========================\n",
        "rows = []\n",
        "for name, builder in [\n",
        "    (\"bilstm_128_emb256+weights\", build_bilstm128),\n",
        "    (\"bigru_128_emb256+weights\",  build_bigru128),\n",
        "]:\n",
        "    print(f\"\\n=== Entrenant {name} ===\")\n",
        "    model = builder()\n",
        "    model.fit(\n",
        "        train_pad_sequences, train_labels_one_hot,\n",
        "        sample_weight=train_sw,\n",
        "        validation_data=(val_pad_sequences, val_labels_one_hot, val_sw),\n",
        "        epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=1\n",
        "    )\n",
        "    _ = model.evaluate(test_pad_sequences, test_labels_one_hot, sample_weight=test_sw, verbose=0)\n",
        "    preds = model.predict(test_pad_sequences, batch_size=batch_size, verbose=0)\n",
        "    rows.append(macro_table_row(name, test_labels_one_hot, preds, len_test_sequences))\n",
        "\n",
        "print_results_table(rows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht6__9dDBbvH",
        "outputId": "00d9dfd0-8ad5-46a6-836a-783fe37940de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Entrenant bilstm_128_emb256+weights ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.1537 - loss: 2.3301 - val_accuracy: 0.2027 - val_loss: 1.2578 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2175 - loss: 0.9879 - val_accuracy: 0.2270 - val_loss: 0.6391 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2358 - loss: 0.4329 - val_accuracy: 0.2327 - val_loss: 0.4184 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2411 - loss: 0.2159 - val_accuracy: 0.2341 - val_loss: 0.3301 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2434 - loss: 0.1240 - val_accuracy: 0.2347 - val_loss: 0.3030 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2443 - loss: 0.0812 - val_accuracy: 0.2353 - val_loss: 0.2766 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2450 - loss: 0.0538 - val_accuracy: 0.2356 - val_loss: 0.2679 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2455 - loss: 0.0376 - val_accuracy: 0.2358 - val_loss: 0.2663 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2457 - loss: 0.0274 - val_accuracy: 0.2359 - val_loss: 0.2697 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2459 - loss: 0.0204 - val_accuracy: 0.2360 - val_loss: 0.2728 - learning_rate: 0.0010\n",
            "\n",
            "=== Entrenant bigru_128_emb256+weights ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1623 - loss: 2.1905 - val_accuracy: 0.2209 - val_loss: 0.8758 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2313 - loss: 0.6072 - val_accuracy: 0.2306 - val_loss: 0.4593 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2388 - loss: 0.2604 - val_accuracy: 0.2328 - val_loss: 0.3619 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2418 - loss: 0.1532 - val_accuracy: 0.2339 - val_loss: 0.3235 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2434 - loss: 0.0975 - val_accuracy: 0.2344 - val_loss: 0.3055 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2444 - loss: 0.0604 - val_accuracy: 0.2351 - val_loss: 0.2956 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2452 - loss: 0.0409 - val_accuracy: 0.2356 - val_loss: 0.2939 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2456 - loss: 0.0279 - val_accuracy: 0.2356 - val_loss: 0.2954 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2456 - loss: 0.0223 - val_accuracy: 0.2357 - val_loss: 0.2943 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2458 - loss: 0.0190 - val_accuracy: 0.2361 - val_loss: 0.2940 - learning_rate: 5.0000e-04\n",
            "\n",
            "modelo                        acc    P_mac  R_mac  F1_mac  P_wgt  R_wgt  F1_wgt\n",
            "-------------------------------------------------------------------------------\n",
            "bilstm_128_emb256+weights     0.8068  0.8277  0.8031  0.7985  0.8074  0.8068  0.8060\n",
            "bigru_128_emb256+weights      0.8058  0.7896  0.7607  0.7443  0.8051  0.8058  0.8032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La bilstm128 ha millorat respecte al seu baseline"
      ],
      "metadata": {
        "id": "Aj1K3gIpFi4E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr2eNm7qJr4F"
      },
      "source": [
        "---\n",
        "\n",
        "<h1><a name=\"section-four\"> 4. Lliurable </a></h1>\n",
        "\n",
        "Heu d'entregar un document PDF de com a **m√†xim 10 p√†gines** que incloga els resultats de tots els exercicis aix√≠ com una explicaci√≥ de cadascun dels resultats i de la modificaci√≥ que heu fet. L'estructura del document √©s:\n",
        "\n",
        "1. Introducci√≥.\n",
        "2. Experiments i Resultats (amb raonament).\n",
        "3. Conclusions.\n",
        "\n",
        "No cal que afegiu el vostre codi al document, podeu entregar el *notebook* juntament amb el document.\n",
        "\n",
        " ---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}